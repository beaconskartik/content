<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Aggregated Listing Metrics - Airbnb System Design</title>
<style>
  :root {
    --primary: #FF5A5F;
    --primary-dark: #E04850;
    --secondary: #00A699;
    --accent: #FC642D;
    --purple: #7B2FF7;
    --blue: #428BF9;
    --dark: #ffffff;
    --darker: #f1f5f9;
    --card-bg: #ffffff;
    --card-border: #e2e8f0;
    --text: #1e293b;
    --text-muted: #4b5563;
    --success: #10b981;
    --warning: #f59e0b;
    --danger: #ef4444;
  }
  * { margin: 0; padding: 0; box-sizing: border-box; }
  body {
    font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
    background: var(--dark);
    color: var(--text);
    line-height: 1.7;
    scroll-behavior: smooth;
  }

  /* HERO */
  .hero {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #6B73FF 100%);
    padding: 60px 40px;
    text-align: center;
    border-bottom: 3px solid var(--primary);
    position: relative;
    overflow: hidden;
  }
  .hero::before {
    content: '';
    position: absolute;
    top: -50%;
    left: -50%;
    width: 200%;
    height: 200%;
    background: radial-gradient(circle at 30% 50%, rgba(255,90,95,0.15) 0%, transparent 50%),
                radial-gradient(circle at 70% 50%, rgba(0,166,153,0.15) 0%, transparent 50%);
    animation: pulse 8s ease-in-out infinite;
  }
  @keyframes pulse {
    0%, 100% { transform: scale(1); }
    50% { transform: scale(1.05); }
  }
  .hero h1 {
    font-size: 2.8em;
    background: linear-gradient(135deg, #ffffff, #e0e7ff, #ffffff);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    position: relative;
    margin-bottom: 10px;
  }
  .hero .subtitle {
    font-size: 1.2em;
    color: rgba(255,255,255,0.9);
    position: relative;
    margin-bottom: 15px;
  }
  .hero .back-link {
    position: relative;
    display: inline-flex;
    align-items: center;
    gap: 8px;
    color: #ffffff;
    text-decoration: none;
    font-size: 0.95em;
    font-weight: 600;
    padding: 10px 24px;
    border-radius: 10px;
    border: 1px solid rgba(255,255,255,0.4);
    background: rgba(255,255,255,0.15);
    transition: all 0.3s;
    margin-bottom: 20px;
  }
  .hero .back-link:hover {
    background: rgba(255,255,255,0.25);
    border-color: #e5e7eb;
    transform: translateX(-3px);
  }
  .badge {
    display: inline-block;
    padding: 4px 14px;
    border-radius: 20px;
    font-size: 0.8em;
    font-weight: 600;
    margin: 5px;
  }
  .badge-red { background: rgba(255,255,255,0.15); color: #ffffff; border: 1px solid rgba(255,255,255,0.3); }
  .badge-green { background: rgba(0,166,153,0.2); color: #ffffff; border: 1px solid var(--secondary); }
  .badge-blue { background: rgba(255,255,255,0.15); color: #ffffff; border: 1px solid rgba(255,255,255,0.3); }
  .badge-purple { background: rgba(255,255,255,0.15); color: #ffffff; border: 1px solid rgba(255,255,255,0.3); }
  .badge-orange { background: rgba(255,255,255,0.15); color: #ffffff; border: 1px solid rgba(255,255,255,0.3); }

  /* NAV */
  .toc {
    background: #f8fafc;
    padding: 24px 40px;
    border-bottom: 1px solid var(--card-border);
    position: sticky;
    top: 0;
    z-index: 100;
    backdrop-filter: blur(10px);
  }
  .toc h2 { color: var(--secondary); margin-bottom: 14px; font-size: 0.9em; text-transform: uppercase; letter-spacing: 2px; }
  .toc-grid {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
  }
  .toc a {
    color: var(--text-muted);
    text-decoration: none;
    padding: 7px 16px;
    border-radius: 8px;
    background: var(--card-bg);
    border: 1px solid #e5e7eb; box-shadow: 0 1px 3px rgba(0,0,0,0.08);
    font-size: 0.82em;
    transition: all 0.3s;
  }
  .toc a:hover {
    color: var(--primary);
    border-color: var(--primary);
    background: rgba(255,90,95,0.1);
  }

  /* SECTIONS */
  .container { max-width: 1300px; margin: 0 auto; padding: 0 30px; }
  section { padding: 50px 0; border-bottom: 1px solid var(--card-border); }
  section:last-child { border-bottom: none; }
  section h2 {
    font-size: 1.9em;
    margin-bottom: 25px;
    display: flex;
    align-items: center;
    gap: 12px;
  }
  section h2 .icon {
    width: 44px;
    height: 44px;
    border-radius: 10px;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 1.2em;
  }
  section h3 {
    font-size: 1.3em;
    color: #ffffff;
    margin: 28px 0 12px;
    padding-left: 12px;
    border-left: 3px solid var(--secondary);
  }
  section h4 {
    font-size: 1.1em;
    color: var(--blue);
    margin: 20px 0 8px;
  }
  p { margin: 8px 0; }

  /* CARDS */
  .card {
    background: var(--card-bg);
    border: 1px solid #e5e7eb; box-shadow: 0 1px 3px rgba(0,0,0,0.08);
    border-radius: 12px;
    padding: 24px;
    margin: 15px 0;
    transition: transform 0.2s, box-shadow 0.2s;
  }
  .card:hover {
    transform: translateY(-2px);
    box-shadow: 0 8px 25px rgba(0,0,0,0.3);
  }
  .card-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 20px;
    margin: 20px 0;
  }
  .card-header {
    font-size: 1.1em;
    font-weight: 700;
    margin-bottom: 10px;
    display: flex;
    align-items: center;
    gap: 8px;
  }

  /* TABLES */
  table {
    width: 100%;
    border-collapse: collapse;
    margin: 15px 0;
    font-size: 0.92em;
  }
  th {
    background: linear-gradient(135deg, rgba(255,90,95,0.15), rgba(0,166,153,0.15));
    color: var(--text);
    padding: 12px 16px;
    text-align: left;
    font-weight: 600;
    border-bottom: 2px solid var(--primary);
  }
  td {
    padding: 10px 16px;
    border-bottom: 1px solid var(--card-border);
  }
  tr:hover td { background: rgba(255,255,255,0.03); }

  /* CODE */
  pre {
    background: #f6f8fa;
    border: 1px solid #e5e7eb; box-shadow: 0 1px 3px rgba(0,0,0,0.08);
    border-radius: 10px;
    padding: 20px;
    overflow-x: auto;
    font-family: 'Cascadia Code', 'Fira Code', 'Consolas', monospace;
    font-size: 0.88em;
    line-height: 1.6;
    margin: 15px 0;
  }
  code {
    font-family: 'Cascadia Code', 'Fira Code', 'Consolas', monospace;
    font-size: 0.9em;
  }
  .keyword { color: #cf222e; }
  .string { color: #0a3069; }
  .comment { color: #6e7781; }
  .type { color: #8250df; }
  .func { color: #0550ae; }
  .number { color: #f0883e; }

  /* TIPS */
  .tip-box {
    border-radius: 12px;
    padding: 20px 24px;
    margin: 20px 0;
    border-left: 4px solid;
  }
  .tip-interview {
    background: rgba(123,47,247,0.1);
    border-color: var(--purple);
  }
  .tip-warning {
    background: rgba(245,158,11,0.1);
    border-color: var(--warning);
  }
  .tip-success {
    background: rgba(16,185,129,0.1);
    border-color: var(--success);
  }
  .tip-danger {
    background: rgba(239,68,68,0.1);
    border-color: var(--danger);
  }
  .tip-info {
    background: rgba(66,139,249,0.08);
    border-color: var(--blue);
  }
  .tip-box .tip-title {
    font-weight: 700;
    margin-bottom: 6px;
    font-size: 0.95em;
  }

  /* FLOW */
  .flow-steps {
    display: flex;
    flex-wrap: wrap;
    gap: 0;
    margin: 20px 0;
    align-items: center;
  }
  .flow-step {
    background: var(--card-bg);
    border: 1px solid #e5e7eb; box-shadow: 0 1px 3px rgba(0,0,0,0.08);
    border-radius: 10px;
    padding: 12px 20px;
    text-align: center;
    font-size: 0.9em;
    min-width: 140px;
  }
  .flow-arrow {
    color: var(--primary);
    font-size: 1.5em;
    padding: 0 5px;
  }

  /* LISTS */
  ul { padding-left: 20px; margin: 8px 0; }
  ol { padding-left: 20px; margin: 8px 0; }
  li { margin: 4px 0; }
  li::marker { color: var(--primary); }

  /* COMPARISON */
  .comparison {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 20px;
    margin: 20px 0;
  }
  .option-a { border-top: 3px solid var(--secondary); }
  .option-b { border-top: 3px solid var(--accent); }

  /* METRIC CARDS */
  .metric-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 15px;
    margin: 20px 0;
  }
  .metric-card {
    background: var(--card-bg);
    border: 1px solid #e5e7eb; box-shadow: 0 1px 3px rgba(0,0,0,0.08);
    border-radius: 12px;
    padding: 20px;
    text-align: center;
  }
  .metric-value {
    font-size: 2em;
    font-weight: 800;
    background: linear-gradient(135deg, var(--primary), var(--accent));
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
  }
  .metric-label {
    color: var(--text-muted);
    font-size: 0.85em;
    margin-top: 4px;
  }

  /* DIAGRAM BOX */
  .diagram-box {
    background: linear-gradient(135deg, var(--card-bg), var(--darker));
    border: 1px solid #e5e7eb; box-shadow: 0 1px 3px rgba(0,0,0,0.08);
    border-radius: 16px;
    padding: 30px;
    margin: 25px 0;
    overflow-x: auto;
  }

  /* CALIBRATION */
  .calibration-grid {
    display: grid;
    grid-template-columns: 1fr;
    gap: 16px;
    margin: 20px 0;
  }
  .calibration-card {
    background: var(--card-bg);
    border: 1px solid #e5e7eb; box-shadow: 0 1px 3px rgba(0,0,0,0.08);
    border-radius: 12px;
    padding: 20px 24px;
    position: relative;
    overflow: hidden;
  }
  .calibration-card::before {
    content: '';
    position: absolute;
    left: 0;
    top: 0;
    bottom: 0;
    width: 4px;
  }
  .cal-strong-no::before { background: var(--danger); }
  .cal-no::before { background: var(--warning); }
  .cal-yes::before { background: var(--success); }
  .cal-strong-yes::before { background: var(--secondary); }
  .calibration-card .cal-label {
    font-weight: 800;
    font-size: 0.85em;
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-bottom: 8px;
  }
  .cal-strong-no .cal-label { color: var(--danger); }
  .cal-no .cal-label { color: var(--warning); }
  .cal-yes .cal-label { color: var(--success); }
  .cal-strong-yes .cal-label { color: var(--success); }

  /* INLINE CODE */
  code.inline {
    background: rgba(255,255,255,0.08);
    padding: 2px 8px;
    border-radius: 4px;
    font-size: 0.88em;
    color: var(--accent);
  }

  /* FOOTER */
  .footer {
    text-align: center;
    padding: 40px 30px;
    color: var(--text-muted);
    font-size: 0.85em;
    border-top: 1px solid #e5e7eb;
  }
  .footer a {
    color: #ffffff;
    text-decoration: none;
  }
  .footer a:hover { color: var(--primary); }

    /* ===== RESPONSIVE ===== */
  @media (max-width: 768px) {
    .hero { padding: 36px 16px 30px; }
    .hero h1 { font-size: 1.7em; }
    .hero .subtitle { font-size: 0.95em; }
    .hero .back-link { font-size: 0.85em; padding: 8px 16px; }
    .hero .stats-row { gap: 16px; margin-top: 18px; }
    .hero .stat-value { font-size: 1.4em; }
    .hero .stat-label { font-size: 0.7em; }
    .toc { padding: 14px 16px; }
    .toc-grid { gap: 6px; }
    .toc a { padding: 5px 12px; font-size: 0.78em; }
    .container { padding: 16px 12px; }
    .card-grid, .card-grid-3, .pricing-grid, .comparison { grid-template-columns: 1fr; gap: 14px; }
    section { padding: 24px 0; }
    section > h2 { font-size: 1.25em; }
    table { font-size: 0.82em; display: block; overflow-x: auto; -webkit-overflow-scrolling: touch; }
    th, td { padding: 8px 10px; white-space: nowrap; }
    pre { font-size: 0.82em; padding: 14px; overflow-x: auto; }
    .diagram-box { overflow-x: auto; -webkit-overflow-scrolling: touch; }
    .diagram-box svg { min-width: 600px; }
    footer { padding: 24px 16px; font-size: 0.8em; }
  }
  @media (max-width: 480px) {
    .hero { padding: 28px 12px 22px; }
    .hero h1 { font-size: 1.35em; line-height: 1.3; }
    .hero .subtitle { font-size: 0.85em; }
    .hero .back-link { font-size: 0.78em; padding: 6px 12px; }
    .hero .stats-row { gap: 8px; }
    .hero .stat-value { font-size: 1.15em; }
    .container { padding: 14px 10px; }
    .toc a { padding: 4px 10px; font-size: 0.72em; }
    section > h2 { font-size: 1.1em; }
    .badge { padding: 3px 10px; font-size: 0.7em; }
    pre { font-size: 0.75em; padding: 10px; }
    table { font-size: 0.75em; }
    th, td { padding: 6px 8px; }
    footer { padding: 18px 12px; }
  }
  @media (max-width: 360px) {
    .hero h1 { font-size: 1.15em; }
    .hero .stat-value { font-size: 1em; }
    .container { padding: 10px 8px; }
  }

  /* === DIAGRAM ZOOM CONTROLS === */
  .diagram-box { position: relative; }
  .diagram-zoom-controls {
    position: absolute; top: 12px; right: 12px; z-index: 10;
    display: flex; gap: 4px; opacity: 0.5; transition: opacity 0.3s;
  }
  .diagram-box:hover .diagram-zoom-controls { opacity: 1; }
  .diagram-zoom-controls button {
    width: 32px; height: 32px; border-radius: 8px; border: 1px solid #e5e7eb;
    background: #ffffff; color: #1e293b; cursor: pointer; font-size: 16px;
    display: flex; align-items: center; justify-content: center;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1); transition: all 0.2s;
    font-family: system-ui; line-height: 1; padding: 0;
  }
  .diagram-zoom-controls button:hover { background: #f1f5f9; border-color: var(--blue); color: var(--blue); }
  .diagram-zoom-controls button:active { transform: scale(0.95); }
  .diagram-zoom-controls .zoom-level {
    font-size: 11px; color: #64748b; display: flex; align-items: center;
    padding: 0 6px; font-weight: 600; min-width: 40px; justify-content: center;
  }
  .diagram-box svg { transition: transform 0.3s ease; transform-origin: center center; }
  .diagram-box.fullscreen {
    position: fixed !important; top: 0; left: 0; width: 100vw; height: 100vh;
    z-index: 9999; background: #ffffff; border-radius: 0; padding: 20px;
    display: flex; align-items: center; justify-content: center;
    overflow: auto;
  }
  .diagram-box.fullscreen .diagram-zoom-controls { opacity: 1; top: 20px; right: 20px; }
</style>
</head>
<body>

<!-- ==================== HERO ==================== -->
<div class="hero">
  <a href="index.html" class="back-link">&#8592; Back to All Topics</a>
  <h1>Aggregated Listing Metrics</h1>
  <p class="subtitle">Host Performance Dashboard -- Data Pipeline System Design</p>
  <div style="margin-top:15px; position:relative;">
    <span class="badge badge-red">Data Pipeline</span>
    <span class="badge badge-green">Consistency</span>
    <span class="badge badge-blue">Aggregation</span>
    <span class="badge badge-purple">PE Interview</span>
    <span class="badge badge-orange">Medium</span>
  </div>
</div>

<!-- ==================== NAV ==================== -->
<nav class="toc">
  <h2>Navigation</h2>
  <div class="toc-grid">
    <a href="#overview">Overview</a>
    <a href="#requirements">Requirements</a>
    <a href="#capacity">Capacity Estimates</a>
    <a href="#approaches">Two Approaches</a>
    <a href="#data-model">Data Model</a>
    <a href="#api">API Design</a>
    <a href="#consistency">Consistency Handling</a>
    <a href="#surging">Follow-up: Surging</a>
    <a href="#gdpr">Follow-up: GDPR</a>
    <a href="#tradeoffs">Trade-offs</a>
    <a href="#interview-tips">Interview Tips</a>
  </div>
</nav>

<div class="container">

<!-- ==================== SECTION 1: OVERVIEW ==================== -->
<section id="overview">
  <h2><span class="icon" style="background:linear-gradient(135deg,rgba(255,90,95,0.2),rgba(252,100,45,0.15)); color:var(--primary);">&#128202;</span> Overview</h2>

  <p>Airbnb hosts manage one or more listings. Each listing has a nightly state: <strong>booked</strong>, <strong>unbooked</strong> (available but not reserved), or <strong>offline</strong> (host blocked the dates). Hosts need a dashboard showing how their properties are performing -- occupancy rate, average nightly rate, and Revenue Per Available Room (RevPAR) -- broken down by day, week, and month.</p>

  <div class="tip-box tip-warning">
    <div class="tip-title">Why This Problem Is Harder Than It Looks</div>
    <p>The raw data that feeds these metrics is scattered across multiple sources of truth. Booking data lives in the reservation service. Pricing data lives in the pricing service. Availability calendars live in the calendar service. None of these are optimized for time-series aggregation queries. Past data is <strong>mutable</strong> -- a refund can retroactively change a past night's revenue. And missed writes (e.g., a booking event that never reached the metrics pipeline) create silent inconsistencies that compound over time.</p>
  </div>

  <h3>The Host Dashboard</h3>
  <p>Imagine a host with 5 listings across two cities. They open their dashboard and want to see:</p>

  <div class="card-grid">
    <div class="card">
      <div class="card-header" style="color:var(--primary);">&#128200; Occupancy Rate</div>
      <p><strong>Formula:</strong> Booked Nights / (Booked + Unbooked Nights)</p>
      <p>Excludes offline nights from the denominator. Shown as percentage by day, week, month, trailing 90 days.</p>
    </div>
    <div class="card">
      <div class="card-header" style="color:var(--secondary);">&#128176; Average Nightly Rate (ANR)</div>
      <p><strong>Formula:</strong> Total Revenue / Booked Nights</p>
      <p>What the host actually earned per booked night after cleaning fees, service fees. Displayed in host's local currency.</p>
    </div>
    <div class="card">
      <div class="card-header" style="color:var(--blue);">&#128179; RevPAR</div>
      <p><strong>Formula:</strong> Total Revenue / Available Nights</p>
      <p>Revenue Per Available Room. Industry-standard metric. Available = booked + unbooked (excludes offline). Incentivizes both high occupancy AND high nightly rate.</p>
    </div>
  </div>

  <h3>Why Standard Queries Won't Work</h3>
  <div class="card">
    <p>A naive approach would be: on every dashboard load, query the booking service for all reservations, join with pricing data, and compute aggregations on the fly. This fails for several reasons:</p>
    <ul>
      <li><strong>Multiple sources of truth:</strong> Booking, pricing, and calendar data live in separate services with different schemas and different consistency guarantees</li>
      <li><strong>Expensive joins:</strong> Computing 6-month trailing RevPAR across 5 listings requires scanning ~900 rows from bookings, joining with pricing records, filtering by calendar state -- all at query time</li>
      <li><strong>Mutable past data:</strong> A guest gets a partial refund for 3 nights in January. The January revenue must be retroactively corrected, changing historical aggregates</li>
      <li><strong>Missed writes:</strong> If a booking event was dropped by the message queue, the metrics will silently diverge from the source of truth with no signal of the error</li>
      <li><strong>Scale:</strong> 7M listings x 365 days = 2.5B daily state rows per year. Real-time joins across this are not feasible at &lt;500ms latency</li>
    </ul>
  </div>

  <div class="tip-box tip-interview">
    <div class="tip-title">Interview Signal</div>
    <p>The interviewer is testing whether you recognize this as a <strong>data consistency problem</strong>, not a math problem. Candidates who jump straight to "just compute the formulas" miss the core challenge: the data feeding those formulas is unreliable, mutable, and scattered across multiple services.</p>
  </div>
</section>

<!-- ==================== SECTION 2: REQUIREMENTS ==================== -->
<section id="requirements">
  <h2><span class="icon" style="background:linear-gradient(135deg,rgba(0,166,153,0.2),rgba(0,166,153,0.15)); color:var(--secondary);">&#128203;</span> Requirements</h2>

  <h3>Functional Requirements</h3>
  <div class="card">
    <table>
      <thead>
        <tr><th>#</th><th>Requirement</th><th>Details</th></tr>
      </thead>
      <tbody>
        <tr>
          <td><span style="color:var(--primary);font-weight:700;">FR-1</span></td>
          <td>Nightly State Tracking</td>
          <td>Track each listing-night as <code class="inline">BOOKED</code>, <code class="inline">UNBOOKED</code>, or <code class="inline">OFFLINE</code>. State can change retroactively (cancellation, refund).</td>
        </tr>
        <tr>
          <td><span style="color:var(--primary);font-weight:700;">FR-2</span></td>
          <td>Earnings by Period</td>
          <td>Show total revenue, ANR, and RevPAR broken down by day, week, and month. Support arbitrary date range queries.</td>
        </tr>
        <tr>
          <td><span style="color:var(--primary);font-weight:700;">FR-3</span></td>
          <td>Past + Future Dates</td>
          <td>Historical data shows actuals (including retroactive corrections). Future data shows projected earnings from confirmed bookings.</td>
        </tr>
        <tr>
          <td><span style="color:var(--primary);font-weight:700;">FR-4</span></td>
          <td>Multi-Listing Aggregation</td>
          <td>Hosts with multiple listings see per-listing metrics AND a portfolio-level rollup. Support filtering by listing subset.</td>
        </tr>
        <tr>
          <td><span style="color:var(--primary);font-weight:700;">FR-5</span></td>
          <td>Currency Handling</td>
          <td>Revenue displayed in host's preferred currency. Multi-currency listings converted at booking-time exchange rate.</td>
        </tr>
      </tbody>
    </table>
  </div>

  <h3>Non-Functional Requirements</h3>
  <div class="card">
    <table>
      <thead>
        <tr><th>#</th><th>Requirement</th><th>Target</th></tr>
      </thead>
      <tbody>
        <tr>
          <td><span style="color:var(--secondary);font-weight:700;">NFR-1</span></td>
          <td>Read Latency</td>
          <td><strong>&lt;500ms p99</strong> for dashboard load. Pre-computed aggregates, not real-time computation.</td>
        </tr>
        <tr>
          <td><span style="color:var(--secondary);font-weight:700;">NFR-2</span></td>
          <td>Consistency</td>
          <td>Handle inconsistencies gracefully. Metrics should converge with source of truth within <strong>1 hour</strong>. Missed writes must be detected and reconciled.</td>
        </tr>
        <tr>
          <td><span style="color:var(--secondary);font-weight:700;">NFR-3</span></td>
          <td>Data Freshness</td>
          <td>Intraday changes (new bookings, cancellations) reflected within <strong>&lt;1 hour</strong>. Daily batch is not sufficient alone.</td>
        </tr>
        <tr>
          <td><span style="color:var(--secondary);font-weight:700;">NFR-4</span></td>
          <td>Availability</td>
          <td><strong>99.9%</strong>. Dashboard is read-heavy and tolerates eventual consistency, but must not show stale data beyond 1 hour.</td>
        </tr>
        <tr>
          <td><span style="color:var(--secondary);font-weight:700;">NFR-5</span></td>
          <td>Scalability</td>
          <td>Support 7M listings, 2M hosts, 2.5B rows/year. Horizontal scaling for both storage and computation.</td>
        </tr>
      </tbody>
    </table>
  </div>

  <div class="tip-box tip-info">
    <div class="tip-title">Scoping Note</div>
    <p>In the interview, clarify: "Do we need real-time streaming updates or is near-real-time (sub-hour) acceptable?" The answer significantly changes the architecture. For Airbnb's use case, sub-hour freshness is sufficient -- hosts don't need second-by-second dashboards.</p>
  </div>
</section>

<!-- ==================== SECTION 3: CAPACITY ==================== -->
<section id="capacity">
  <h2><span class="icon" style="background:linear-gradient(135deg,rgba(66,139,249,0.2),rgba(66,139,249,0.08)); color:var(--blue);">&#128290;</span> Capacity Estimates</h2>

  <div class="metric-grid">
    <div class="metric-card">
      <div class="metric-value">7M</div>
      <div class="metric-label">Active Listings</div>
    </div>
    <div class="metric-card">
      <div class="metric-value">2M</div>
      <div class="metric-label">Active Hosts</div>
    </div>
    <div class="metric-card">
      <div class="metric-value">3.5</div>
      <div class="metric-label">Avg Listings / Host</div>
    </div>
    <div class="metric-card">
      <div class="metric-value">2.5B</div>
      <div class="metric-label">Rows / Year</div>
    </div>
  </div>

  <h3>Storage Calculations</h3>
  <div class="card">
    <h4>Daily Metrics (listing_daily_metrics)</h4>
    <pre><span class="comment">-- Per listing per day: 1 row</span>
<span class="comment">-- 7M listings x 365 days = 2.555B rows/year</span>
<span class="comment">-- Row size: listing_id(8B) + date(4B) + state(1B) + revenue(8B) + currency(3B)</span>
<span class="comment">--           + nightly_rate(8B) + last_updated(8B) + flags(4B) = ~44 bytes</span>
<span class="comment">-- Annual storage: 2.555B x 44B = ~112 GB/year (raw)</span>
<span class="comment">-- With indexes: ~170 GB/year</span>
<span class="comment">-- 3-year retention: ~510 GB -- fits in single large Postgres or sharded</span></pre>

    <h4>Aggregate Metrics (listing_aggregate_metrics)</h4>
    <pre><span class="comment">-- Per listing: 12 monthly + 52 weekly = 64 rollup rows/year</span>
<span class="comment">-- 7M x 64 = 448M rows/year</span>
<span class="comment">-- Row size: ~80 bytes (includes counts + totals)</span>
<span class="comment">-- Annual storage: 448M x 80B = ~36 GB/year</span></pre>

    <h4>Read Traffic</h4>
    <pre><span class="comment">-- ~100K unique hosts check dashboard per day</span>
<span class="comment">-- Average 2 page views per session</span>
<span class="comment">-- Peak hours: 60% of traffic in 8-hour window</span>

<span class="comment">-- Average QPS: 200K / 86400 = ~2.3 QPS (very low)</span>
<span class="comment">-- Peak QPS:   120K / 28800 = ~4.2 QPS</span>
<span class="comment">-- This is read-light. No need for aggressive caching infrastructure.</span>
<span class="comment">-- A single read replica can handle this easily.</span></pre>
  </div>

  <div class="tip-box tip-success">
    <div class="tip-title">Key Insight: This is a Storage + Consistency Problem, Not a Scale Problem</div>
    <p>The QPS is trivially low. The hard part is NOT handling traffic -- it is keeping 2.5B rows/year consistent across multiple source-of-truth services when past data is mutable and writes can be missed. Do not waste interview time designing for "massive read scale" -- the interviewer wants to hear about data consistency.</p>
  </div>

  <h3>Write Traffic</h3>
  <div class="card">
    <pre><span class="comment">-- Booking events: ~1.5M bookings/day globally</span>
<span class="comment">-- Each booking touches avg 4.5 nights = ~6.75M row updates/day</span>
<span class="comment">-- Cancellations/modifications: ~150K/day</span>
<span class="comment">-- Price changes (refunds): ~50K/day</span>
<span class="comment">-- Calendar changes (host blocks/unblocks): ~500K/day</span>

<span class="comment">-- Total write events: ~7.45M/day = ~86 writes/sec avg</span>
<span class="comment">-- Peak: ~250 writes/sec (3x burst)</span>
<span class="comment">-- Very manageable for a single-writer database</span></pre>
  </div>
</section>

<!-- ==================== SECTION 4: TWO APPROACHES ==================== -->
<section id="approaches">
  <h2><span class="icon" style="background:linear-gradient(135deg,rgba(123,47,247,0.2),rgba(123,47,247,0.08)); color:var(--purple);">&#9878;</span> Two Solution Approaches</h2>

  <div class="tip-box tip-interview">
    <div class="tip-title">Critical Interview Moment</div>
    <p>The interviewer expects you to present <strong>two fundamentally different approaches</strong> and reason about trade-offs between them. This is what separates L5 from L6. Both approaches need a mechanism to capture writes to sources of truth -- typically via pub/sub -- rather than having every client update the metrics store directly.</p>
  </div>

  <div class="comparison">
    <!-- APPROACH A -->
    <div class="card option-a">
      <div class="card-header" style="color:var(--secondary);">Approach A: Offline Batch + Intraday Cache</div>
      <p style="color:var(--text-muted);margin-bottom:16px;">Daily warehouse job bootstraps stats; cache captures intraday delta</p>

      <h4>How It Works</h4>
      <ol>
        <li><strong>Nightly batch job</strong> (midnight UTC) scans all sources of truth (booking DB, pricing DB, calendar DB) and computes the canonical daily/weekly/monthly metrics for every listing</li>
        <li><strong>Writes to metrics store</strong> -- replaces all computed aggregates</li>
        <li><strong>Intraday cache layer</strong> -- after batch run, subscribe to real-time events (new bookings, cancellations, price changes) via pub/sub and maintain a cache of deltas since last batch</li>
        <li><strong>Dashboard read path:</strong> base metrics (from batch) + intraday deltas (from cache) = current view</li>
        <li><strong>At midnight:</strong> new batch run replaces everything, intraday cache is reset</li>
      </ol>

      <h4>Architecture Flow</h4>
      <div class="diagram-box" style="padding:20px;overflow-x:auto;">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1100 520" font-family="'Segoe UI', system-ui, sans-serif" style="min-width:900px;width:100%;">
          <defs>
            <marker id="arr-a" markerWidth="8" markerHeight="6" refX="8" refY="3" orient="auto"><path d="M0,0 L8,3 L0,6 Z" fill="#94a3b8"/></marker>
            <marker id="arr-a-g" markerWidth="8" markerHeight="6" refX="8" refY="3" orient="auto"><path d="M0,0 L8,3 L0,6 Z" fill="#00A699"/></marker>
            <marker id="arr-a-o" markerWidth="8" markerHeight="6" refX="8" refY="3" orient="auto"><path d="M0,0 L8,3 L0,6 Z" fill="#FC642D"/></marker>
            <linearGradient id="g1a" x1="0" y1="0" x2="1" y2="1"><stop offset="0%" stop-color="#FF5A5F"/><stop offset="100%" stop-color="#E04850"/></linearGradient>
            <linearGradient id="g2a" x1="0" y1="0" x2="1" y2="1"><stop offset="0%" stop-color="#00A699"/><stop offset="100%" stop-color="#008B80"/></linearGradient>
            <linearGradient id="g3a" x1="0" y1="0" x2="1" y2="1"><stop offset="0%" stop-color="#428BF9"/><stop offset="100%" stop-color="#3070D0"/></linearGradient>
            <linearGradient id="g4a" x1="0" y1="0" x2="1" y2="1"><stop offset="0%" stop-color="#7B2FF7"/><stop offset="100%" stop-color="#6020C0"/></linearGradient>
            <linearGradient id="g5a" x1="0" y1="0" x2="1" y2="1"><stop offset="0%" stop-color="#FC642D"/><stop offset="100%" stop-color="#D04E20"/></linearGradient>
            <filter id="shadow-a"><feDropShadow dx="2" dy="3" stdDeviation="4" flood-opacity="0.12"/></filter>
          </defs>

          <!-- TITLE -->
          <text x="550" y="28" text-anchor="middle" fill="#1e293b" font-size="16" font-weight="700">Approach A: Batch + Intraday Cache Architecture</text>

          <!-- ===== SOURCES (left column) ===== -->
          <g filter="url(#shadow-a)">
            <rect x="20" y="60" width="140" height="60" rx="10" fill="url(#g1a)" opacity="0.95"/>
            <text x="90" y="84" text-anchor="middle" fill="#fff" font-size="12" font-weight="700">Booking Service</text>
            <text x="90" y="100" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="9">Reservations DB</text>
          </g>
          <g filter="url(#shadow-a)">
            <rect x="20" y="140" width="140" height="60" rx="10" fill="url(#g1a)" opacity="0.95"/>
            <text x="90" y="164" text-anchor="middle" fill="#fff" font-size="12" font-weight="700">Listing Service</text>
            <text x="90" y="180" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="9">Pricing / Calendar</text>
          </g>
          <g filter="url(#shadow-a)">
            <rect x="20" y="220" width="140" height="60" rx="10" fill="url(#g1a)" opacity="0.95"/>
            <text x="90" y="244" text-anchor="middle" fill="#fff" font-size="12" font-weight="700">Payment Service</text>
            <text x="90" y="260" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="9">Revenue / Payouts</text>
          </g>
          <text x="90" y="52" text-anchor="middle" fill="#94a3b8" font-size="10" font-weight="600" text-transform="uppercase" letter-spacing="1.5">SOURCES</text>

          <!-- ===== DATA WAREHOUSE (batch path - top) ===== -->
          <g filter="url(#shadow-a)">
            <rect x="240" y="60" width="150" height="70" rx="10" fill="url(#g2a)" opacity="0.95"/>
            <text x="315" y="88" text-anchor="middle" fill="#fff" font-size="12" font-weight="700">Data Warehouse</text>
            <text x="315" y="106" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="9">Nightly ETL / Hive</text>
          </g>
          <text x="315" y="52" text-anchor="middle" fill="#94a3b8" font-size="10" font-weight="600" letter-spacing="1.5">BATCH PATH</text>

          <!-- Arrow: Sources -> Data Warehouse -->
          <line x1="160" y1="90" x2="232" y2="90" stroke="#00A699" stroke-width="2" marker-end="url(#arr-a-g)"/>
          <text x="196" y="84" text-anchor="middle" fill="#00A699" font-size="8">ETL</text>

          <!-- ===== Batch Compute ===== -->
          <g filter="url(#shadow-a)">
            <rect x="440" y="60" width="150" height="70" rx="10" fill="url(#g2a)" opacity="0.95"/>
            <text x="515" y="88" text-anchor="middle" fill="#fff" font-size="12" font-weight="700">Spark / Hive Job</text>
            <text x="515" y="106" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="9">Daily batch compute</text>
          </g>

          <!-- Arrow: DW -> Spark -->
          <line x1="390" y1="95" x2="432" y2="95" stroke="#00A699" stroke-width="2" marker-end="url(#arr-a-g)"/>

          <!-- ===== KAFKA (center, event capture) ===== -->
          <g filter="url(#shadow-a)" transform="translate(280,200)">
            <rect x="0" y="0" width="120" height="65" rx="8" fill="#f8fafc" stroke="#ef4444" stroke-width="2"/>
            <!-- Kafka icon: 3 nodes -->
            <circle cx="25" cy="20" r="6" fill="#ef4444"/>
            <circle cx="50" cy="12" r="6" fill="#ef4444"/>
            <circle cx="50" cy="32" r="6" fill="#ef4444"/>
            <line x1="31" y1="18" x2="44" y2="14" stroke="#ef4444" stroke-width="1.5"/>
            <line x1="31" y1="22" x2="44" y2="30" stroke="#ef4444" stroke-width="1.5"/>
            <text x="78" y="18" fill="#fff" font-size="9" font-weight="700">KAFKA</text>
            <text x="60" y="55" text-anchor="middle" fill="#94a3b8" font-size="8">CDC Events</text>
          </g>
          <text x="340" y="195" text-anchor="middle" fill="#94a3b8" font-size="10" font-weight="600" letter-spacing="1.5">EVENT BUS</text>

          <!-- Arrows: Sources -> Kafka -->
          <line x1="160" y1="170" x2="220" y2="220" stroke="#ef4444" stroke-width="1.5" stroke-dasharray="5,3" marker-end="url(#arr-a)"/>
          <line x1="160" y1="250" x2="220" y2="240" stroke="#ef4444" stroke-width="1.5" stroke-dasharray="5,3" marker-end="url(#arr-a)"/>

          <!-- ===== REAL-TIME PATH (bottom) ===== -->
          <text x="515" y="195" text-anchor="middle" fill="#94a3b8" font-size="10" font-weight="600" letter-spacing="1.5">REAL-TIME PATH</text>
          <g filter="url(#shadow-a)">
            <rect x="440" y="200" width="150" height="70" rx="10" fill="url(#g5a)" opacity="0.95"/>
            <text x="515" y="228" text-anchor="middle" fill="#fff" font-size="12" font-weight="700">Stream Processor</text>
            <text x="515" y="246" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="9">Flink / Real-time deltas</text>
          </g>

          <!-- Arrow: Kafka -> Stream Processor -->
          <line x1="400" y1="235" x2="432" y2="235" stroke="#FC642D" stroke-width="2" marker-end="url(#arr-a-o)"/>

          <!-- Arrow: Kafka -> Data Warehouse (batch) -->
          <line x1="340" y1="200" x2="340" y2="138" stroke="#00A699" stroke-width="1.5" stroke-dasharray="5,3" marker-end="url(#arr-a-g)"/>
          <text x="350" y="170" fill="#00A699" font-size="8">nightly</text>

          <!-- ===== METRICS STORE (PostgreSQL) ===== -->
          <g filter="url(#shadow-a)" transform="translate(670,70)">
            <!-- DB Cylinder -->
            <ellipse cx="55" cy="12" rx="50" ry="12" fill="#428BF9"/>
            <rect x="5" y="12" width="100" height="50" fill="#3070D0"/>
            <ellipse cx="55" cy="62" rx="50" ry="12" fill="#3070D0"/>
            <ellipse cx="55" cy="12" rx="50" ry="12" fill="#428BF9" opacity="0.7"/>
            <text x="55" y="38" text-anchor="middle" fill="#fff" font-size="11" font-weight="700">PostgreSQL</text>
            <text x="55" y="52" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="8">Metrics Store</text>
          </g>
          <text x="725" y="52" text-anchor="middle" fill="#94a3b8" font-size="10" font-weight="600" letter-spacing="1.5">STORAGE</text>

          <!-- Arrow: Spark -> Metrics Store (batch) -->
          <line x1="590" y1="95" x2="668" y2="95" stroke="#00A699" stroke-width="2" marker-end="url(#arr-a-g)"/>
          <text x="629" y="88" text-anchor="middle" fill="#00A699" font-size="8">batch write</text>

          <!-- ===== REDIS (intraday cache) ===== -->
          <g filter="url(#shadow-a)" transform="translate(670,200)">
            <rect x="5" y="0" width="100" height="70" rx="8" fill="#f8fafc" stroke="#ef4444" stroke-width="1.5"/>
            <!-- Redis diamond icon -->
            <polygon points="55,10 75,30 55,50 35,30" fill="none" stroke="#ef4444" stroke-width="2"/>
            <polygon points="55,18 67,30 55,42 43,30" fill="#ef4444" opacity="0.5"/>
            <text x="55" y="64" text-anchor="middle" fill="#ef4444" font-size="9" font-weight="700">REDIS</text>
          </g>

          <!-- Arrow: Stream Processor -> Redis -->
          <line x1="590" y1="235" x2="668" y2="235" stroke="#FC642D" stroke-width="2" marker-end="url(#arr-a-o)"/>
          <text x="629" y="228" text-anchor="middle" fill="#FC642D" font-size="8">real-time</text>

          <!-- ===== METRICS API SERVICE ===== -->
          <g filter="url(#shadow-a)">
            <rect x="830" y="130" width="140" height="70" rx="10" fill="url(#g4a)" opacity="0.95"/>
            <!-- API shield icon -->
            <path d="M870,155 L870,145 C870,140 880,135 880,135 C880,135 890,140 890,145 L890,155 C890,162 880,168 880,168 C880,168 870,162 870,155 Z" fill="none" stroke="#fff" stroke-width="1.5"/>
            <polyline points="875,153 879,157 886,148" fill="none" stroke="#fff" stroke-width="1.5"/>
            <text x="930" y="160" text-anchor="middle" fill="#fff" font-size="11" font-weight="700">Metrics API</text>
            <text x="930" y="176" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="8">Base + Delta merge</text>
          </g>
          <text x="900" y="122" text-anchor="middle" fill="#94a3b8" font-size="10" font-weight="600" letter-spacing="1.5">SERVING</text>

          <!-- Arrow: Postgres -> API -->
          <line x1="780" y1="110" x2="822" y2="145" stroke="#94a3b8" stroke-width="1.5" marker-end="url(#arr-a)"/>
          <!-- Arrow: Redis -> API -->
          <line x1="780" y1="235" x2="822" y2="185" stroke="#94a3b8" stroke-width="1.5" marker-end="url(#arr-a)"/>
          <text x="810" y="210" fill="#94a3b8" font-size="8" transform="rotate(-40,810,210)">intraday deltas</text>
          <text x="810" y="130" fill="#94a3b8" font-size="8" transform="rotate(20,810,130)">base metrics</text>

          <!-- ===== HOST DASHBOARD ===== -->
          <g filter="url(#shadow-a)">
            <rect x="1010" y="135" width="70" height="60" rx="10" fill="#f8fafc" stroke="#7B2FF7" stroke-width="1.5"/>
            <!-- Monitor icon -->
            <rect x="1025" y="148" width="40" height="26" rx="3" fill="none" stroke="#7B2FF7" stroke-width="1.5"/>
            <line x1="1045" y1="174" x2="1045" y2="182" stroke="#7B2FF7" stroke-width="1.5"/>
            <line x1="1035" y1="182" x2="1055" y2="182" stroke="#7B2FF7" stroke-width="1.5"/>
            <text x="1045" y="163" text-anchor="middle" fill="#7B2FF7" font-size="7">HOST</text>
          </g>

          <!-- Arrow: API -> Dashboard -->
          <line x1="970" y1="165" x2="1005" y2="165" stroke="#94a3b8" stroke-width="1.5" marker-end="url(#arr-a)"/>

          <!-- ===== MIDNIGHT RESET ANNOTATION ===== -->
          <rect x="640" y="290" width="200" height="44" rx="8" fill="rgba(245,158,11,0.1)" stroke="#f59e0b" stroke-width="1" stroke-dasharray="4,3"/>
          <text x="740" y="310" text-anchor="middle" fill="#f59e0b" font-size="10" font-weight="600">Midnight Reset</text>
          <text x="740" y="324" text-anchor="middle" fill="#94a3b8" font-size="8">Batch replaces base, cache clears</text>

          <!-- Dashed line: Midnight to Redis + Postgres -->
          <line x1="720" y1="290" x2="720" y2="280" stroke="#f59e0b" stroke-width="1" stroke-dasharray="3,3" marker-end="url(#arr-a)"/>

          <!-- ===== LABELS on paths ===== -->
          <rect x="240" y="345" width="350" height="50" rx="8" fill="rgba(0,166,153,0.06)" stroke="rgba(0,166,153,0.25)" stroke-width="1"/>
          <text x="260" y="365" fill="#00A699" font-size="10" font-weight="700">Batch Path (daily):</text>
          <text x="260" y="380" fill="#94a3b8" font-size="9">Sources -> Data Warehouse -> Spark Job -> PostgreSQL (authoritative)</text>

          <rect x="240" y="405" width="350" height="50" rx="8" fill="rgba(252,100,45,0.06)" stroke="rgba(252,100,45,0.25)" stroke-width="1"/>
          <text x="260" y="425" fill="#FC642D" font-size="10" font-weight="700">Real-Time Path (seconds):</text>
          <text x="260" y="440" fill="#94a3b8" font-size="9">CDC Events -> Kafka -> Stream Processor -> Redis (intraday deltas)</text>

          <!-- Legend -->
          <g transform="translate(20,360)">
            <text x="0" y="0" fill="#1e293b" font-size="10" font-weight="700">Legend</text>
            <line x1="0" y1="14" x2="30" y2="14" stroke="#00A699" stroke-width="2"/>
            <text x="36" y="18" fill="#94a3b8" font-size="9">Batch (sync)</text>
            <line x1="0" y1="32" x2="30" y2="32" stroke="#FC642D" stroke-width="2"/>
            <text x="36" y="36" fill="#94a3b8" font-size="9">Real-time (sync)</text>
            <line x1="0" y1="50" x2="30" y2="50" stroke="#ef4444" stroke-width="1.5" stroke-dasharray="5,3"/>
            <text x="36" y="54" fill="#94a3b8" font-size="9">Async (CDC events)</text>
          </g>

          <!-- ===== NUMBERED STEP CIRCLES ===== -->
          <!-- Step 1: Source Services -> Kafka (CDC events) -->
          <circle cx="200" cy="200" r="10" fill="#FF5A5F" stroke="#fff" stroke-width="1.5"/>
          <text x="200" y="204" fill="#fff" font-size="10" font-weight="800" text-anchor="middle">1</text>

          <!-- Step 2: Kafka -> Data Warehouse (batch ingestion) -->
          <circle cx="330" cy="168" r="10" fill="#FF5A5F" stroke="#fff" stroke-width="1.5"/>
          <text x="330" y="172" fill="#fff" font-size="10" font-weight="800" text-anchor="middle">2</text>

          <!-- Step 3: Data Warehouse -> Spark/Hive Job (daily aggregation) -->
          <circle cx="412" cy="82" r="10" fill="#FF5A5F" stroke="#fff" stroke-width="1.5"/>
          <text x="412" y="86" fill="#fff" font-size="10" font-weight="800" text-anchor="middle">3</text>

          <!-- Step 4: Spark Job -> PostgreSQL Metrics Store (write aggregates) -->
          <circle cx="630" cy="82" r="10" fill="#FF5A5F" stroke="#fff" stroke-width="1.5"/>
          <text x="630" y="86" fill="#fff" font-size="10" font-weight="800" text-anchor="middle">4</text>

          <!-- Step 5: Kafka -> Stream Processor (real-time intraday) -->
          <circle cx="418" cy="222" r="10" fill="#FF5A5F" stroke="#fff" stroke-width="1.5"/>
          <text x="418" y="226" fill="#fff" font-size="10" font-weight="800" text-anchor="middle">5</text>

          <!-- Step 6: Stream Processor -> Redis (cache intraday deltas) -->
          <circle cx="630" cy="222" r="10" fill="#FF5A5F" stroke="#fff" stroke-width="1.5"/>
          <text x="630" y="226" fill="#fff" font-size="10" font-weight="800" text-anchor="middle">6</text>

          <!-- Step 7: Host Dashboard -> Metrics API (HTTPS request) -->
          <circle cx="990" cy="152" r="10" fill="#FF5A5F" stroke="#fff" stroke-width="1.5"/>
          <text x="990" y="156" fill="#fff" font-size="10" font-weight="800" text-anchor="middle">7</text>

          <!-- Step 8: Metrics API -> PostgreSQL + Redis -> merged response -->
          <circle cx="810" cy="165" r="10" fill="#FF5A5F" stroke="#fff" stroke-width="1.5"/>
          <text x="810" y="169" fill="#fff" font-size="10" font-weight="800" text-anchor="middle">8</text>

          <!-- Step 9: Reconciliation Job (periodic consistency check) -->
          <circle cx="638" cy="310" r="10" fill="#FF5A5F" stroke="#fff" stroke-width="1.5"/>
          <text x="638" y="314" fill="#fff" font-size="10" font-weight="800" text-anchor="middle">9</text>

        </svg>
      </div>

      <!-- ===== REQUEST FLOW REFERENCE ===== -->
      <h4 style="color:var(--blue);">Request Flow Reference</h4>
      <table style="margin:12px 0 20px;">
        <thead>
          <tr><th>Step</th><th>From</th><th>To</th><th>Protocol / Mechanism</th><th>Notes</th></tr>
        </thead>
        <tbody>
          <tr><td><strong style="color:var(--primary);">1</strong></td><td>Source Services (Booking/Listing/Payment)</td><td>Kafka</td><td>CDC (Change Data Capture)</td><td>Events emitted on every state change in source DBs</td></tr>
          <tr><td><strong style="color:var(--primary);">2</strong></td><td>Kafka</td><td>Data Warehouse</td><td>Batch ingestion (daily)</td><td>Nightly ETL pulls accumulated events into Hive tables</td></tr>
          <tr><td><strong style="color:var(--primary);">3</strong></td><td>Data Warehouse</td><td>Spark / Hive Job</td><td>Scheduled job (midnight UTC)</td><td>Full recompute of all listing aggregates from warehouse</td></tr>
          <tr><td><strong style="color:var(--primary);">4</strong></td><td>Spark Job</td><td>PostgreSQL Metrics Store</td><td>Batch write (JDBC / bulk upsert)</td><td>Replaces base metrics with authoritative daily computation</td></tr>
          <tr><td><strong style="color:var(--primary);">5</strong></td><td>Kafka</td><td>Stream Processor (Flink)</td><td>Streaming consume</td><td>Real-time intraday delta computation from CDC events</td></tr>
          <tr><td><strong style="color:var(--primary);">6</strong></td><td>Stream Processor</td><td>Redis</td><td>Write (intraday cache)</td><td>Stores deltas since last batch run; reset at midnight</td></tr>
          <tr><td><strong style="color:var(--primary);">7</strong></td><td>Host Dashboard</td><td>Metrics API</td><td>HTTPS GET</td><td>Host requests current performance metrics for their listings</td></tr>
          <tr><td><strong style="color:var(--primary);">8</strong></td><td>Metrics API</td><td>PostgreSQL + Redis</td><td>Parallel read + merge</td><td>base_metrics (PG) + intraday_delta (Redis) = current view</td></tr>
          <tr><td><strong style="color:var(--primary);">9</strong></td><td>Reconciliation Job</td><td>Sources + Metrics Store</td><td>Periodic cron (every 6h)</td><td>Compares aggregates against source-of-truth; corrects drift</td></tr>
        </tbody>
      </table>

      <!-- ===== HAPPY PATH ===== -->
      <h4 style="color:var(--success);">Happy Path</h4>
      <div class="tip-box tip-success" style="margin:8px 0 20px;">
        <div class="tip-title">End-to-End Sunny Day Flow</div>
        <p><strong>1.</strong> A host receives a new booking -- the Booking Service writes to its DB and a CDC event fires to Kafka.
        <strong>2.</strong> The event is consumed by both paths in parallel: the <em>batch path</em> accumulates it in the Data Warehouse for the next nightly job, while the <em>real-time path</em> sends it through the Stream Processor which increments the intraday delta in Redis.
        <strong>3.</strong> The host opens their dashboard. The Metrics API reads the last nightly aggregate from PostgreSQL and the intraday delta from Redis, merges them, and returns a response showing the updated booking count and revenue.
        <strong>4.</strong> At midnight UTC, the Spark batch job recomputes all aggregates from the warehouse (incorporating the booking), writes the new canonical metrics to PostgreSQL, and the Redis intraday cache is reset to zero. The cycle repeats.</p>
      </div>

      <!-- ===== FAILURE PATHS ===== -->
      <h4 style="color:var(--danger);">Failure Paths</h4>
      <table style="margin:12px 0 20px;">
        <thead>
          <tr><th>Failure Scenario</th><th>Impact</th><th>Detection</th><th>Mitigation / Recovery</th></tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Missed CDC Event</strong></td>
            <td>One booking/cancellation not reflected in metrics; host sees stale data</td>
            <td>Reconciliation job detects mismatch between source DB counts and aggregated metrics</td>
            <td>Reconciliation corrects the drift within 6 hours; nightly batch fully recomputes within 24h</td>
          </tr>
          <tr>
            <td><strong>Spark Batch Job Failure</strong></td>
            <td>Base metrics remain stale (from previous day); intraday deltas still applied so partial freshness</td>
            <td>Job monitoring alerts on failure; dashboard shows <code class="inline">last_updated</code> timestamp &gt; 24h</td>
            <td>Auto-retry with exponential backoff; manual re-trigger; intraday cache bridges the gap</td>
          </tr>
          <tr>
            <td><strong>Redis Cache Inconsistency at Midnight Reset</strong></td>
            <td>Brief window where dashboard shows stale batch data with no intraday corrections</td>
            <td>Monitoring on cache-miss rate spike at midnight boundary</td>
            <td>Atomic swap: write new batch to staging table, then swap + reset cache in a single transaction; use watermark overlap (T-5min)</td>
          </tr>
          <tr>
            <td><strong>Race Condition During Reconciliation</strong></td>
            <td>Reconciliation reads source while new events are in-flight; corrects to an already-stale snapshot</td>
            <td>Audit log shows reconciliation overwrites followed immediately by event-driven updates</td>
            <td>Use snapshot isolation with consistent read timestamp; apply reconciliation deltas idempotently using source_version</td>
          </tr>
        </tbody>
      </table>

      <h4 style="color:var(--danger);">Race Conditions</h4>
      <ul>
        <li><strong>Midnight boundary:</strong> A booking event arrives at 11:59:58 PM. The batch job started at midnight with a snapshot that does NOT include this booking. The intraday cache is then reset. Result: booking is lost from metrics until the NEXT batch run (24 hours later).</li>
        <li><strong>Mitigation:</strong> Use a watermark. Batch processes data up to T-5min. Intraday cache starts from T-5min. Overlap ensures no gaps.</li>
        <li><strong>Cache reset ordering:</strong> If cache resets BEFORE new batch data is written, there is a brief window where dashboard shows stale batch data with no intraday corrections. Use atomic swap: write new batch to staging table, then swap + reset cache in a single transaction.</li>
      </ul>

      <h4 style="color:var(--success);">Strengths</h4>
      <ul>
        <li>Batch job acts as periodic full reconciliation against source of truth</li>
        <li>Self-healing: any inconsistency from missed events is corrected within 24 hours</li>
        <li>Simpler operational model -- batch jobs are well-understood</li>
        <li>Data warehouse already exists at Airbnb scale</li>
      </ul>

      <h4 style="color:var(--danger);">Weaknesses</h4>
      <ul>
        <li>Complex midnight handoff logic with race conditions</li>
        <li>Intraday cache must handle same event types as batch -- duplicated logic</li>
        <li>Batch job duration limits freshness ceiling (if batch takes 2 hours, data can be 2hr stale)</li>
        <li>Harder to extend with new metric types (requires both batch + cache changes)</li>
      </ul>
    </div>

    <!-- APPROACH B -->
    <div class="card option-b">
      <div class="card-header" style="color:var(--accent);">Approach B: Online Stats Maintenance</div>
      <p style="color:var(--text-muted);margin-bottom:16px;">Maintain metrics in real-time via event-driven updates; periodic offline reconciliation</p>

      <h4>How It Works</h4>
      <ol>
        <li><strong>Event-driven pipeline</strong> subscribes to all source-of-truth changes via pub/sub (booking created, booking cancelled, price changed, calendar updated)</li>
        <li><strong>Stats updater service</strong> processes each event and applies the delta directly to the metrics store (increment booked_nights, adjust revenue, etc.)</li>
        <li><strong>Dashboard read path:</strong> reads directly from the metrics store -- no cache merging needed</li>
        <li><strong>Periodic reconciliation job</strong> (e.g., every 6 hours) compares metrics store values against source-of-truth services and corrects any drift</li>
        <li><strong>If reconciliation finds mismatch:</strong> full recalculation of the affected listing's metrics for the affected time period</li>
      </ol>

      <h4>Architecture Flow</h4>
      <div class="diagram-box" style="padding:20px;overflow-x:auto;">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1100 540" font-family="'Segoe UI', system-ui, sans-serif" style="min-width:900px;width:100%;">
          <defs>
            <marker id="arr-b" markerWidth="8" markerHeight="6" refX="8" refY="3" orient="auto"><path d="M0,0 L8,3 L0,6 Z" fill="#94a3b8"/></marker>
            <marker id="arr-b-o" markerWidth="8" markerHeight="6" refX="8" refY="3" orient="auto"><path d="M0,0 L8,3 L0,6 Z" fill="#FC642D"/></marker>
            <marker id="arr-b-g" markerWidth="8" markerHeight="6" refX="8" refY="3" orient="auto"><path d="M0,0 L8,3 L0,6 Z" fill="#00A699"/></marker>
            <linearGradient id="g1b" x1="0" y1="0" x2="1" y2="1"><stop offset="0%" stop-color="#FF5A5F"/><stop offset="100%" stop-color="#E04850"/></linearGradient>
            <linearGradient id="g2b" x1="0" y1="0" x2="1" y2="1"><stop offset="0%" stop-color="#00A699"/><stop offset="100%" stop-color="#008B80"/></linearGradient>
            <linearGradient id="g3b" x1="0" y1="0" x2="1" y2="1"><stop offset="0%" stop-color="#428BF9"/><stop offset="100%" stop-color="#3070D0"/></linearGradient>
            <linearGradient id="g4b" x1="0" y1="0" x2="1" y2="1"><stop offset="0%" stop-color="#7B2FF7"/><stop offset="100%" stop-color="#6020C0"/></linearGradient>
            <linearGradient id="g5b" x1="0" y1="0" x2="1" y2="1"><stop offset="0%" stop-color="#FC642D"/><stop offset="100%" stop-color="#D04E20"/></linearGradient>
            <filter id="shadow-b"><feDropShadow dx="2" dy="3" stdDeviation="4" flood-opacity="0.12"/></filter>
          </defs>

          <!-- TITLE -->
          <text x="550" y="28" text-anchor="middle" fill="#1e293b" font-size="16" font-weight="700">Approach B: Online Stats Maintenance + Reconciliation</text>

          <!-- ===== SOURCES (left) ===== -->
          <text x="90" y="56" text-anchor="middle" fill="#94a3b8" font-size="10" font-weight="600" letter-spacing="1.5">SOURCES</text>
          <g filter="url(#shadow-b)">
            <rect x="20" y="68" width="140" height="55" rx="10" fill="url(#g1b)" opacity="0.95"/>
            <text x="90" y="90" text-anchor="middle" fill="#fff" font-size="12" font-weight="700">Booking Service</text>
            <text x="90" y="106" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="9">Create / Cancel / Modify</text>
          </g>
          <g filter="url(#shadow-b)">
            <rect x="20" y="135" width="140" height="55" rx="10" fill="url(#g1b)" opacity="0.95"/>
            <text x="90" y="157" text-anchor="middle" fill="#fff" font-size="12" font-weight="700">Listing Service</text>
            <text x="90" y="173" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="9">Pricing / Calendar</text>
          </g>
          <g filter="url(#shadow-b)">
            <rect x="20" y="202" width="140" height="55" rx="10" fill="url(#g1b)" opacity="0.95"/>
            <text x="90" y="224" text-anchor="middle" fill="#fff" font-size="12" font-weight="700">Payment Service</text>
            <text x="90" y="240" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="9">Revenue / Payouts</text>
          </g>

          <!-- ===== KAFKA ===== -->
          <text x="290" y="56" text-anchor="middle" fill="#94a3b8" font-size="10" font-weight="600" letter-spacing="1.5">EVENT BUS</text>
          <g filter="url(#shadow-b)" transform="translate(230,68)">
            <rect x="0" y="0" width="120" height="65" rx="8" fill="#f8fafc" stroke="#ef4444" stroke-width="2"/>
            <circle cx="25" cy="20" r="6" fill="#ef4444"/>
            <circle cx="50" cy="12" r="6" fill="#ef4444"/>
            <circle cx="50" cy="32" r="6" fill="#ef4444"/>
            <line x1="31" y1="18" x2="44" y2="14" stroke="#ef4444" stroke-width="1.5"/>
            <line x1="31" y1="22" x2="44" y2="30" stroke="#ef4444" stroke-width="1.5"/>
            <text x="78" y="18" fill="#fff" font-size="9" font-weight="700">KAFKA</text>
            <text x="60" y="55" text-anchor="middle" fill="#94a3b8" font-size="8">CDC Events</text>
          </g>

          <!-- Arrows: Sources -> Kafka -->
          <line x1="160" y1="95" x2="225" y2="95" stroke="#ef4444" stroke-width="1.5" stroke-dasharray="5,3" marker-end="url(#arr-b)"/>
          <line x1="160" y1="162" x2="210" y2="115" stroke="#ef4444" stroke-width="1.5" stroke-dasharray="5,3" marker-end="url(#arr-b)"/>
          <line x1="160" y1="230" x2="210" y2="130" stroke="#ef4444" stroke-width="1.5" stroke-dasharray="5,3" marker-end="url(#arr-b)"/>

          <!-- ===== STATS UPDATER ===== -->
          <text x="490" y="56" text-anchor="middle" fill="#94a3b8" font-size="10" font-weight="600" letter-spacing="1.5">PROCESSING</text>
          <g filter="url(#shadow-b)">
            <rect x="415" y="68" width="150" height="65" rx="10" fill="url(#g5b)" opacity="0.95"/>
            <text x="490" y="92" text-anchor="middle" fill="#fff" font-size="12" font-weight="700">Stats Updater</text>
            <text x="490" y="110" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="9">Idempotent Consumer</text>
            <text x="490" y="122" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="8">event_id dedup with TTL</text>
          </g>

          <!-- Arrow: Kafka -> Stats Updater -->
          <line x1="350" y1="100" x2="408" y2="100" stroke="#FC642D" stroke-width="2" marker-end="url(#arr-b-o)"/>

          <!-- ===== METRICS STORE (PostgreSQL) ===== -->
          <text x="710" y="56" text-anchor="middle" fill="#94a3b8" font-size="10" font-weight="600" letter-spacing="1.5">METRICS STORE</text>
          <g filter="url(#shadow-b)" transform="translate(655,68)">
            <ellipse cx="55" cy="12" rx="50" ry="12" fill="#428BF9"/>
            <rect x="5" y="12" width="100" height="45" fill="#3070D0"/>
            <ellipse cx="55" cy="57" rx="50" ry="12" fill="#3070D0"/>
            <ellipse cx="55" cy="12" rx="50" ry="12" fill="#428BF9" opacity="0.7"/>
            <text x="55" y="36" text-anchor="middle" fill="#fff" font-size="11" font-weight="700">PostgreSQL</text>
            <text x="55" y="50" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="8">Real-time metrics</text>
          </g>

          <!-- Arrow: Stats Updater -> Metrics Store -->
          <line x1="565" y1="100" x2="650" y2="100" stroke="#FC642D" stroke-width="2" marker-end="url(#arr-b-o)"/>
          <text x="607" y="92" text-anchor="middle" fill="#FC642D" font-size="8">delta writes</text>

          <!-- ===== METRICS API ===== -->
          <text x="910" y="56" text-anchor="middle" fill="#94a3b8" font-size="10" font-weight="600" letter-spacing="1.5">SERVING</text>
          <g filter="url(#shadow-b)">
            <rect x="840" y="68" width="140" height="65" rx="10" fill="url(#g4b)" opacity="0.95"/>
            <path d="M865,92 L865,82 C865,77 875,72 875,72 C875,72 885,77 885,82 L885,92 C885,99 875,105 875,105 C875,105 865,99 865,92 Z" fill="none" stroke="#fff" stroke-width="1.3"/>
            <polyline points="870,90 874,94 882,85" fill="none" stroke="#fff" stroke-width="1.3"/>
            <text x="930" y="93" text-anchor="middle" fill="#fff" font-size="11" font-weight="700">Metrics API</text>
            <text x="930" y="110" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="8">Direct read (no merge)</text>
          </g>

          <!-- Arrow: Metrics Store -> API -->
          <line x1="760" y1="100" x2="833" y2="100" stroke="#94a3b8" stroke-width="1.5" marker-end="url(#arr-b)"/>

          <!-- ===== HOST DASHBOARD ===== -->
          <g filter="url(#shadow-b)">
            <rect x="1020" y="72" width="60" height="56" rx="10" fill="#f8fafc" stroke="#7B2FF7" stroke-width="1.5"/>
            <rect x="1032" y="82" width="36" height="22" rx="3" fill="none" stroke="#7B2FF7" stroke-width="1.5"/>
            <line x1="1050" y1="104" x2="1050" y2="112" stroke="#7B2FF7" stroke-width="1.5"/>
            <line x1="1040" y1="112" x2="1060" y2="112" stroke="#7B2FF7" stroke-width="1.5"/>
            <text x="1050" y="95" text-anchor="middle" fill="#7B2FF7" font-size="7">HOST</text>
          </g>

          <!-- Arrow: API -> Dashboard -->
          <line x1="980" y1="100" x2="1015" y2="100" stroke="#94a3b8" stroke-width="1.5" marker-end="url(#arr-b)"/>

          <!-- ===== RECONCILIATION SECTION (bottom) ===== -->
          <rect x="130" y="290" width="660" height="195" rx="14" fill="rgba(0,166,153,0.04)" stroke="rgba(0,166,153,0.25)" stroke-width="1.5" stroke-dasharray="6,4"/>
          <text x="460" y="312" text-anchor="middle" fill="#00A699" font-size="13" font-weight="700">Reconciliation Flow (every 6 hours)</text>

          <!-- Reconciliation Job (gear icon) -->
          <g filter="url(#shadow-b)">
            <rect x="150" y="335" width="140" height="65" rx="10" fill="url(#g2b)" opacity="0.95"/>
            <!-- Gear icon -->
            <circle cx="195" cy="367" r="10" fill="none" stroke="#fff" stroke-width="1.5"/>
            <circle cx="195" cy="367" r="4" fill="#fff"/>
            <line x1="195" y1="354" x2="195" y2="358" stroke="#fff" stroke-width="2"/>
            <line x1="195" y1="376" x2="195" y2="380" stroke="#fff" stroke-width="2"/>
            <line x1="182" y1="367" x2="186" y2="367" stroke="#fff" stroke-width="2"/>
            <line x1="204" y1="367" x2="208" y2="367" stroke="#fff" stroke-width="2"/>
            <text x="245" y="362" text-anchor="middle" fill="#fff" font-size="10" font-weight="700">Recon Job</text>
            <text x="245" y="378" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="8">Scheduled cron</text>
          </g>

          <!-- Source of Truth (compare) -->
          <g filter="url(#shadow-b)">
            <rect x="340" y="335" width="140" height="65" rx="10" fill="url(#g2b)" opacity="0.95"/>
            <text x="410" y="362" text-anchor="middle" fill="#fff" font-size="10" font-weight="700">Source of Truth</text>
            <text x="410" y="378" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="8">Full scan compare</text>
          </g>

          <!-- Diff Detector -->
          <g filter="url(#shadow-b)">
            <rect x="530" y="335" width="130" height="65" rx="10" fill="url(#g2b)" opacity="0.95"/>
            <text x="595" y="362" text-anchor="middle" fill="#fff" font-size="10" font-weight="700">Diff Detector</text>
            <text x="595" y="378" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="8">Find mismatches</text>
          </g>

          <!-- Arrows in reconciliation flow -->
          <line x1="290" y1="367" x2="333" y2="367" stroke="#00A699" stroke-width="2" marker-end="url(#arr-b-g)"/>
          <line x1="480" y1="367" x2="523" y2="367" stroke="#00A699" stroke-width="2" marker-end="url(#arr-b-g)"/>

          <!-- Arrow: Diff Detector -> Metrics Store (patch) -->
          <line x1="660" y1="367" x2="710" y2="367" stroke="#00A699" stroke-width="2"/>
          <line x1="710" y1="367" x2="710" y2="145" stroke="#00A699" stroke-width="2" marker-end="url(#arr-b-g)"/>
          <text x="720" y="265" fill="#00A699" font-size="8" transform="rotate(-90,720,265)">patch corrections</text>

          <!-- Arrow: Recon Job reads from Sources (up-left) -->
          <line x1="220" y1="335" x2="130" y2="260" stroke="#00A699" stroke-width="1.5" stroke-dasharray="5,3" marker-end="url(#arr-b-g)"/>
          <text x="150" y="300" fill="#00A699" font-size="8">reads sources</text>

          <!-- Arrow: Recon Job reads from Metrics Store -->
          <line x1="410" y1="335" x2="710" y2="145" stroke="#00A699" stroke-width="1" stroke-dasharray="5,3"/>
          <text x="560" y="240" fill="#00A699" font-size="8" transform="rotate(-22,560,240)">reads metrics</text>

          <!-- Version guard annotation -->
          <rect x="150" y="415" width="440" height="38" rx="6" fill="rgba(245,158,11,0.06)" stroke="#f59e0b" stroke-width="1"/>
          <text x="170" y="435" fill="#f59e0b" font-size="9" font-weight="600">Version Guard:</text>
          <text x="268" y="435" fill="#94a3b8" font-size="9">Only patches rows not updated since scan time (compare-and-swap)</text>

          <!-- Legend -->
          <g transform="translate(20,460)">
            <text x="0" y="0" fill="#1e293b" font-size="10" font-weight="700">Legend</text>
            <line x1="0" y1="14" x2="30" y2="14" stroke="#FC642D" stroke-width="2"/>
            <text x="36" y="18" fill="#94a3b8" font-size="9">Real-time event path</text>
            <line x1="150" y1="14" x2="180" y2="14" stroke="#00A699" stroke-width="2"/>
            <text x="186" y="18" fill="#94a3b8" font-size="9">Reconciliation path</text>
            <line x1="310" y1="14" x2="340" y2="14" stroke="#ef4444" stroke-width="1.5" stroke-dasharray="5,3"/>
            <text x="346" y="18" fill="#94a3b8" font-size="9">Async (CDC events)</text>
          </g>
        </svg>
      </div>

      <h4 style="color:var(--danger);">Race Conditions</h4>
      <ul>
        <li><strong>Reconciliation during writes:</strong> Reconciliation reads source of truth at time T1, then reads metrics store at T2. Between T1 and T2, a new event updated the metrics. Reconciliation sees a mismatch and "corrects" it by reverting the valid update.</li>
        <li><strong>Mitigation:</strong> Use versioned rows with <code class="inline">last_updated</code> timestamps. Reconciliation only patches rows that have NOT been updated since T1. Alternatively, use compare-and-swap: only update if current value matches expected stale value.</li>
        <li><strong>Duplicate events:</strong> Kafka may deliver the same booking event twice. Without idempotency, revenue gets double-counted.</li>
        <li><strong>Mitigation:</strong> Idempotent processing using event_id deduplication. Store processed event_ids with TTL.</li>
      </ul>

      <h4 style="color:var(--success);">Strengths</h4>
      <ul>
        <li>Near real-time freshness (seconds to minutes, not hours)</li>
        <li>Single read path -- no cache + base merging complexity</li>
        <li>Easier to add new metrics (add new event handler)</li>
        <li>Reconciliation catches drift without full recomputation</li>
      </ul>

      <h4 style="color:var(--danger);">Weaknesses</h4>
      <ul>
        <li>Reconciliation race conditions are subtle and dangerous</li>
        <li>Between reconciliation runs, inconsistencies persist silently</li>
        <li>Requires idempotent processing -- harder to implement correctly</li>
        <li>No natural "reset point" like the batch approach has at midnight</li>
      </ul>
    </div>
  </div>

  <h3>Shared Requirement: Pub/Sub on Source-of-Truth Changes</h3>
  <div class="card">
    <p>Both approaches require capturing mutations to the underlying data sources. The critical design decision is: <strong>who publishes the events?</strong></p>
    <table>
      <thead>
        <tr><th>Option</th><th>Mechanism</th><th>Pros</th><th>Cons</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>Application-level events</td>
          <td>Booking service publishes <code class="inline">BookingCreated</code> event after committing</td>
          <td>Clean schema, business semantics</td>
          <td>Can miss events if publish fails after commit (dual-write problem)</td>
        </tr>
        <tr>
          <td>CDC (Change Data Capture)</td>
          <td>Debezium reads binlog from booking DB</td>
          <td>Guaranteed to capture all writes, no dual-write</td>
          <td>Raw DB changes, need to reconstruct business events</td>
        </tr>
        <tr>
          <td>Transactional Outbox</td>
          <td>Write event to outbox table in same transaction as booking</td>
          <td>Atomic with business write, clean schema</td>
          <td>Requires outbox relay (Debezium on outbox table), adds latency</td>
        </tr>
      </tbody>
    </table>

    <div class="tip-box tip-success" style="margin-top:15px;">
      <div class="tip-title">Recommended: Transactional Outbox Pattern</div>
      <p>For Airbnb's scale, the transactional outbox provides the best balance. The booking service writes the booking record AND an event record in the same database transaction. A relay process (CDC on the outbox table) publishes events to Kafka. This eliminates dual-write inconsistency while maintaining clean business event schemas.</p>
    </div>
  </div>
</section>

<!-- ==================== SECTION 5: DATA MODEL ==================== -->
<section id="data-model">
  <h2><span class="icon" style="background:linear-gradient(135deg,rgba(252,100,45,0.2),rgba(252,100,45,0.08)); color:var(--accent);">&#128451;</span> Data Model</h2>

  <h3>Core Tables</h3>

  <h4>listing_daily_metrics</h4>
  <p>The lowest-granularity fact table. One row per listing per calendar date. This is the source from which all aggregates are computed.</p>
  <div class="card">
    <pre><span class="keyword">CREATE TABLE</span> <span class="func">listing_daily_metrics</span> (
    <span class="type">listing_id</span>       <span class="keyword">BIGINT</span>       <span class="keyword">NOT NULL</span>,
    <span class="type">date</span>             <span class="keyword">DATE</span>         <span class="keyword">NOT NULL</span>,
    <span class="type">state</span>            <span class="keyword">ENUM</span>(<span class="string">'BOOKED'</span>, <span class="string">'UNBOOKED'</span>, <span class="string">'OFFLINE'</span>) <span class="keyword">NOT NULL</span>,
    <span class="type">revenue_cents</span>    <span class="keyword">BIGINT</span>       <span class="keyword">DEFAULT</span> <span class="number">0</span>,    <span class="comment">-- net after refunds, in booking currency</span>
    <span class="type">currency</span>         <span class="keyword">CHAR</span>(<span class="number">3</span>)      <span class="keyword">NOT NULL</span>,    <span class="comment">-- ISO 4217 (USD, EUR, etc.)</span>
    <span class="type">nightly_rate</span>     <span class="keyword">BIGINT</span>       <span class="keyword">DEFAULT</span> <span class="number">0</span>,    <span class="comment">-- listed price (cents)</span>
    <span class="type">booking_id</span>       <span class="keyword">BIGINT</span>       <span class="keyword">NULL</span>,         <span class="comment">-- NULL if unbooked/offline</span>
    <span class="type">source_version</span>   <span class="keyword">BIGINT</span>       <span class="keyword">NOT NULL</span>,    <span class="comment">-- monotonic; for idempotent updates</span>
    <span class="type">last_updated</span>     <span class="keyword">TIMESTAMP</span>    <span class="keyword">NOT NULL DEFAULT CURRENT_TIMESTAMP</span>,

    <span class="keyword">PRIMARY KEY</span> (<span class="type">listing_id</span>, <span class="type">date</span>)
);

<span class="comment">-- Partition by date range (monthly partitions) for efficient time-range queries</span>
<span class="comment">-- and easy data lifecycle management (drop old partitions)</span>

<span class="keyword">CREATE INDEX</span> idx_daily_host_lookup
    <span class="keyword">ON</span> listing_daily_metrics (<span class="type">listing_id</span>, <span class="type">date</span> <span class="keyword">DESC</span>);</pre>
  </div>

  <h4>listing_aggregate_metrics</h4>
  <p>Pre-computed rollups by week and month. Recomputed from daily metrics on write events or by batch job.</p>
  <div class="card">
    <pre><span class="keyword">CREATE TABLE</span> <span class="func">listing_aggregate_metrics</span> (
    <span class="type">listing_id</span>       <span class="keyword">BIGINT</span>       <span class="keyword">NOT NULL</span>,
    <span class="type">period_type</span>      <span class="keyword">ENUM</span>(<span class="string">'WEEK'</span>, <span class="string">'MONTH'</span>) <span class="keyword">NOT NULL</span>,
    <span class="type">period_start</span>     <span class="keyword">DATE</span>         <span class="keyword">NOT NULL</span>,
    <span class="type">period_end</span>       <span class="keyword">DATE</span>         <span class="keyword">NOT NULL</span>,
    <span class="type">booked_nights</span>    <span class="keyword">INT</span>          <span class="keyword">NOT NULL DEFAULT</span> <span class="number">0</span>,
    <span class="type">unbooked_nights</span>  <span class="keyword">INT</span>          <span class="keyword">NOT NULL DEFAULT</span> <span class="number">0</span>,
    <span class="type">offline_nights</span>   <span class="keyword">INT</span>          <span class="keyword">NOT NULL DEFAULT</span> <span class="number">0</span>,
    <span class="type">total_revenue</span>    <span class="keyword">BIGINT</span>       <span class="keyword">NOT NULL DEFAULT</span> <span class="number">0</span>,  <span class="comment">-- cents, converted to host currency</span>
    <span class="type">currency</span>         <span class="keyword">CHAR</span>(<span class="number">3</span>)      <span class="keyword">NOT NULL</span>,
    <span class="type">occupancy_rate</span>   <span class="keyword">DECIMAL</span>(<span class="number">5</span>,<span class="number">4</span>),  <span class="comment">-- pre-computed for fast reads</span>
    <span class="type">avg_nightly_rate</span> <span class="keyword">BIGINT</span>,              <span class="comment">-- cents</span>
    <span class="type">revpar</span>           <span class="keyword">BIGINT</span>,              <span class="comment">-- cents</span>
    <span class="type">last_reconciled</span>  <span class="keyword">TIMESTAMP</span>,           <span class="comment">-- when last verified against SoT</span>
    <span class="type">last_updated</span>     <span class="keyword">TIMESTAMP</span>    <span class="keyword">NOT NULL DEFAULT CURRENT_TIMESTAMP</span>,

    <span class="keyword">PRIMARY KEY</span> (<span class="type">listing_id</span>, <span class="type">period_type</span>, <span class="type">period_start</span>)
);

<span class="keyword">CREATE INDEX</span> idx_agg_host_period
    <span class="keyword">ON</span> listing_aggregate_metrics (<span class="type">listing_id</span>, <span class="type">period_type</span>, <span class="type">period_start</span> <span class="keyword">DESC</span>);</pre>
  </div>

  <h4>metrics_change_log</h4>
  <p>Append-only audit log for consistency tracking. Every update to daily or aggregate metrics is logged here. Used by reconciliation jobs to detect and diagnose drift.</p>
  <div class="card">
    <pre><span class="keyword">CREATE TABLE</span> <span class="func">metrics_change_log</span> (
    <span class="type">log_id</span>           <span class="keyword">BIGINT AUTO_INCREMENT PRIMARY KEY</span>,
    <span class="type">listing_id</span>       <span class="keyword">BIGINT</span>       <span class="keyword">NOT NULL</span>,
    <span class="type">date</span>             <span class="keyword">DATE</span>         <span class="keyword">NOT NULL</span>,
    <span class="type">change_type</span>      <span class="keyword">ENUM</span>(<span class="string">'EVENT_UPDATE'</span>, <span class="string">'BATCH_UPDATE'</span>, <span class="string">'RECONCILIATION'</span>, <span class="string">'MANUAL_FIX'</span>),
    <span class="type">source_event_id</span>  <span class="keyword">VARCHAR</span>(<span class="number">64</span>),   <span class="comment">-- for idempotency and tracing</span>
    <span class="type">old_state</span>        <span class="keyword">VARCHAR</span>(<span class="number">10</span>),
    <span class="type">new_state</span>        <span class="keyword">VARCHAR</span>(<span class="number">10</span>),
    <span class="type">old_revenue</span>      <span class="keyword">BIGINT</span>,
    <span class="type">new_revenue</span>      <span class="keyword">BIGINT</span>,
    <span class="type">created_at</span>       <span class="keyword">TIMESTAMP</span>    <span class="keyword">NOT NULL DEFAULT CURRENT_TIMESTAMP</span>,

    <span class="keyword">INDEX</span> idx_log_listing_date (<span class="type">listing_id</span>, <span class="type">date</span>),
    <span class="keyword">INDEX</span> idx_log_event_id (<span class="type">source_event_id</span>)
);</pre>
  </div>

  <h3>Host-to-Listing Mapping</h3>
  <div class="card">
    <p>The dashboard needs to know which listings belong to which host. This mapping lives in the listing service, NOT in the metrics store. The API layer joins host_id -> listing_ids from the listing service, then queries the metrics store by listing_id.</p>
    <pre><span class="comment">-- This table lives in the Listing Service, not in the metrics DB</span>
<span class="comment">-- Queried at API layer to resolve host_id -> listing_ids</span>
<span class="keyword">SELECT</span> listing_id <span class="keyword">FROM</span> listings <span class="keyword">WHERE</span> host_id = <span class="number">:host_id</span>;</pre>
  </div>

  <h3>Sharding Strategy</h3>
  <div class="card">
    <table>
      <thead>
        <tr><th>Table</th><th>Shard Key</th><th>Rationale</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>listing_daily_metrics</td>
          <td><code class="inline">listing_id</code></td>
          <td>All queries are per-listing. Time-range queries for a single listing hit one shard. Cross-listing aggregation (host portfolio) requires scatter-gather across shards.</td>
        </tr>
        <tr>
          <td>listing_aggregate_metrics</td>
          <td><code class="inline">listing_id</code></td>
          <td>Same as daily. Co-locate with daily table on same shard for efficient recomputation.</td>
        </tr>
        <tr>
          <td>metrics_change_log</td>
          <td><code class="inline">listing_id</code></td>
          <td>Audit trail co-located with the metrics it tracks. Write-append only, TTL-based retention (90 days).</td>
        </tr>
      </tbody>
    </table>
  </div>
</section>

<!-- ==================== SECTION 6: API DESIGN ==================== -->
<section id="api">
  <h2><span class="icon" style="background:linear-gradient(135deg,rgba(245,158,11,0.2),rgba(245,158,11,0.06)); color:var(--warning);">&#128268;</span> API Design</h2>

  <h3>Primary Dashboard Endpoint</h3>
  <div class="card">
    <pre><span class="keyword">GET</span> <span class="string">/api/v1/hosts/{host_id}/metrics</span>

<span class="comment">Query Parameters:</span>
  <span class="type">period</span>       = <span class="string">day</span> | <span class="string">week</span> | <span class="string">month</span>         <span class="comment">-- aggregation granularity</span>
  <span class="type">start</span>        = <span class="string">2025-01-01</span>                  <span class="comment">-- inclusive start date</span>
  <span class="type">end</span>          = <span class="string">2025-06-30</span>                  <span class="comment">-- inclusive end date</span>
  <span class="type">listing_ids</span>  = <span class="string">123,456,789</span>                 <span class="comment">-- optional filter (default: all host listings)</span>
  <span class="type">currency</span>     = <span class="string">USD</span>                         <span class="comment">-- display currency (default: host preference)</span>

<span class="comment">Headers:</span>
  <span class="type">Authorization</span>: Bearer {jwt_token}
  <span class="type">Accept</span>: application/json

<span class="comment">Response:</span>
{
  <span class="string">"host_id"</span>: <span class="number">42</span>,
  <span class="string">"period"</span>: <span class="string">"month"</span>,
  <span class="string">"currency"</span>: <span class="string">"USD"</span>,
  <span class="string">"data_freshness"</span>: <span class="string">"2025-06-15T14:32:00Z"</span>,
  <span class="string">"portfolio_summary"</span>: {
    <span class="string">"total_revenue"</span>: <span class="number">4523000</span>,        <span class="comment">// cents</span>
    <span class="string">"occupancy_rate"</span>: <span class="number">0.7234</span>,
    <span class="string">"avg_nightly_rate"</span>: <span class="number">18500</span>,       <span class="comment">// cents</span>
    <span class="string">"revpar"</span>: <span class="number">13380</span>,                <span class="comment">// cents</span>
    <span class="string">"total_booked_nights"</span>: <span class="number">245</span>,
    <span class="string">"total_available_nights"</span>: <span class="number">338</span>
  },
  <span class="string">"listings"</span>: [
    {
      <span class="string">"listing_id"</span>: <span class="number">123</span>,
      <span class="string">"listing_name"</span>: <span class="string">"Downtown Loft"</span>,
      <span class="string">"periods"</span>: [
        {
          <span class="string">"period_start"</span>: <span class="string">"2025-01-01"</span>,
          <span class="string">"period_end"</span>: <span class="string">"2025-01-31"</span>,
          <span class="string">"booked_nights"</span>: <span class="number">22</span>,
          <span class="string">"unbooked_nights"</span>: <span class="number">6</span>,
          <span class="string">"offline_nights"</span>: <span class="number">3</span>,
          <span class="string">"revenue"</span>: <span class="number">385000</span>,
          <span class="string">"occupancy_rate"</span>: <span class="number">0.7857</span>,
          <span class="string">"avg_nightly_rate"</span>: <span class="number">17500</span>,
          <span class="string">"revpar"</span>: <span class="number">13750</span>
        }
        <span class="comment">// ... more periods</span>
      ]
    }
    <span class="comment">// ... more listings</span>
  ]
}</pre>
  </div>

  <h3>API Read Path (Internal Flow)</h3>
  <div class="card">
    <div class="flow-steps">
      <div class="flow-step">Client Request<br><small>GET /hosts/:id/metrics</small></div>
      <div class="flow-arrow">&#8594;</div>
      <div class="flow-step">Auth + Rate Limit<br><small>Verify JWT, check host_id ownership</small></div>
      <div class="flow-arrow">&#8594;</div>
      <div class="flow-step">Listing Service<br><small>host_id -> listing_ids</small></div>
      <div class="flow-arrow">&#8594;</div>
      <div class="flow-step">Metrics Store<br><small>Query aggregate table</small></div>
      <div class="flow-arrow">&#8594;</div>
      <div class="flow-step">Response Builder<br><small>Portfolio rollup + format</small></div>
    </div>

    <div class="tip-box tip-info" style="margin-top:20px;">
      <div class="tip-title">Approach A Variation</div>
      <p>If using the offline+cache approach, the Metrics Store step becomes: (1) read base from aggregate table, (2) read deltas from intraday cache, (3) merge. The API layer performs the merge at read time.</p>
    </div>
  </div>

  <h3>Single Listing Daily Detail</h3>
  <div class="card">
    <pre><span class="keyword">GET</span> <span class="string">/api/v1/listings/{listing_id}/daily-metrics</span>

<span class="comment">Query Parameters:</span>
  <span class="type">start</span>  = <span class="string">2025-01-01</span>
  <span class="type">end</span>    = <span class="string">2025-01-31</span>

<span class="comment">Response: Array of daily states with revenue per night</span>
<span class="comment">Used for: calendar heatmap view, drilling into specific days</span></pre>
  </div>
</section>

<!-- ==================== SECTION 7: CONSISTENCY ==================== -->
<section id="consistency">
  <h2><span class="icon" style="background:linear-gradient(135deg,rgba(239,68,68,0.2),rgba(239,68,68,0.06)); color:var(--danger);">&#128274;</span> Consistency Handling</h2>

  <div class="tip-box tip-danger">
    <div class="tip-title">This Is the Hardest Part of the Design</div>
    <p>The interviewer will spend significant time probing your understanding of consistency edge cases. The metrics system is a <strong>derived data store</strong> -- its correctness depends entirely on faithfully reflecting mutations across multiple source-of-truth services. Every missed event, every duplicate, every out-of-order delivery creates silent data corruption.</p>
  </div>

  <h3>1. Missed Writes Detection</h3>
  <div class="card">
    <h4>Problem</h4>
    <p>A booking is created in the booking service, but the event is lost (Kafka consumer crashes, network partition, poison message). The metrics store never learns about this booking. The host's occupancy rate is silently lower than reality.</p>

    <h4>Detection Strategy</h4>
    <table>
      <thead>
        <tr><th>Method</th><th>How It Works</th><th>Latency to Detect</th></tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Checksum reconciliation</strong></td>
          <td>Periodically (every 6 hours), for each listing, compute a checksum over the source-of-truth data (booking count, total revenue for the period) and compare against metrics store. Mismatch triggers recalculation.</td>
          <td>Up to 6 hours</td>
        </tr>
        <tr>
          <td><strong>Event counter comparison</strong></td>
          <td>Source services publish a running event count. Metrics consumer tracks its own count. If they diverge, some events were missed.</td>
          <td>Minutes (near real-time)</td>
        </tr>
        <tr>
          <td><strong>Batch full-scan (Approach A)</strong></td>
          <td>Daily batch job recomputes everything from source of truth. Any accumulated drift is automatically corrected.</td>
          <td>Up to 24 hours</td>
        </tr>
      </tbody>
    </table>

    <h4>Resolution</h4>
    <pre><span class="comment">-- Reconciliation pseudo-code</span>
<span class="keyword">FOR EACH</span> listing_id <span class="keyword">IN</span> affected_listings:
    source_data = booking_service.get_nights(listing_id, period)
    metrics_data = metrics_store.get_daily(listing_id, period)

    <span class="keyword">FOR EACH</span> date <span class="keyword">IN</span> period:
        <span class="keyword">IF</span> source_data[date] != metrics_data[date]:
            metrics_store.upsert(listing_id, date, source_data[date])
            change_log.append(listing_id, date, <span class="string">'RECONCILIATION'</span>,
                              metrics_data[date], source_data[date])

    <span class="comment">-- Recompute affected aggregate periods</span>
    recompute_aggregates(listing_id, affected_weeks, affected_months)</pre>
  </div>

  <h3>2. Idempotent Event Processing</h3>
  <div class="card">
    <h4>Problem</h4>
    <p>Kafka delivers the same <code class="inline">BookingCreated</code> event twice (at-least-once delivery). Without idempotency, the second delivery double-counts the revenue.</p>

    <h4>Solution: source_version + event deduplication</h4>
    <pre><span class="comment">-- Each event carries a monotonically increasing version per listing+date</span>
<span class="comment">-- The metrics store only applies updates with a HIGHER version</span>

<span class="keyword">UPDATE</span> listing_daily_metrics
<span class="keyword">SET</span>    state = <span class="string">:new_state</span>,
       revenue_cents = <span class="string">:new_revenue</span>,
       source_version = <span class="string">:new_version</span>,
       last_updated = NOW()
<span class="keyword">WHERE</span>  listing_id = <span class="string">:listing_id</span>
  <span class="keyword">AND</span>  date = <span class="string">:date</span>
  <span class="keyword">AND</span>  source_version &lt; <span class="string">:new_version</span>;

<span class="comment">-- If 0 rows affected: either duplicate event or stale event. Safe to ignore.</span>
<span class="comment">-- This makes processing idempotent AND handles out-of-order delivery.</span></pre>

    <div class="tip-box tip-success" style="margin-top:15px;">
      <div class="tip-title">Why source_version beats event_id dedup</div>
      <p>Storing processed event_ids for deduplication requires a separate dedup store with TTL management. Using a monotonic version on the row itself is simpler: it handles both duplicates AND out-of-order delivery in a single conditional update. The version comes from the source of truth (e.g., the booking table's row version).</p>
    </div>
  </div>

  <h3>3. Temporal Caching (Approach A Specific)</h3>
  <div class="card">
    <h4>The Midnight Handoff Problem</h4>
    <p>In the offline+cache approach, the transition from "yesterday's batch + today's cache" to "today's batch + empty cache" is the most dangerous moment.</p>

    <div class="diagram-box">
      <pre style="background:transparent;border:none;padding:0;">
Timeline (midnight boundary):

  23:55  23:56  23:57  23:58  23:59  00:00  00:01  00:02  00:03
  --|------|------|------|------|------|------|------|------|--
              Event E1 arrives            Batch job starts
              (cached in Redis)           (reads data up to 23:55)

                                          Cache reset at 00:01

  PROBLEM: E1 was cached, but batch didn't capture it.
           Cache was reset. E1 is now LOST.

  FIX: Watermark overlap
  - Batch processes data up to 23:55 (T - 5 min)
  - Cache retains events from 23:50 onward (T - 10 min)
  - After batch writes, cache events OLDER than 23:55 are dropped
  - Events between 23:55 and 00:01 survive in cache
  - No gap, some overlap (which is safe because reads merge idempotently)</pre>
    </div>
  </div>

  <h3>4. Retroactive Mutations (Refunds / Price Changes)</h3>
  <div class="card">
    <h4>Problem</h4>
    <p>A guest receives a partial refund for a stay that happened 3 weeks ago. The historical revenue for those nights must be corrected. This affects daily metrics AND all aggregate periods that included those nights.</p>

    <h4>Solution: Cascading Update</h4>
    <pre><span class="comment">-- 1. Receive RefundProcessed event</span>
<span class="comment">-- Event contains: booking_id, affected_dates, new_revenue_per_night</span>

<span class="keyword">FOR EACH</span> (listing_id, date, new_revenue) <span class="keyword">IN</span> refund_event.affected_nights:
    <span class="comment">-- Update daily metric</span>
    <span class="keyword">UPDATE</span> listing_daily_metrics
    <span class="keyword">SET</span>    revenue_cents = new_revenue,
           source_version = <span class="string">:new_version</span>,
           last_updated = NOW()
    <span class="keyword">WHERE</span>  listing_id = <span class="string">:listing_id</span> <span class="keyword">AND</span> date = <span class="string">:date</span>
      <span class="keyword">AND</span>  source_version &lt; <span class="string">:new_version</span>;

    <span class="comment">-- Recompute affected aggregate periods</span>
    <span class="comment">-- The week containing this date</span>
    <span class="comment">-- The month containing this date</span>
    recompute_aggregate(listing_id, <span class="string">'WEEK'</span>, week_of(date));
    recompute_aggregate(listing_id, <span class="string">'MONTH'</span>, month_of(date));

<span class="comment">-- Note: aggregate recomputation reads from listing_daily_metrics,</span>
<span class="comment">-- NOT from the source of truth. This is efficient but means</span>
<span class="comment">-- daily metrics must be correct first.</span></pre>
  </div>

  <h3>5. Consistency Guarantees Summary</h3>
  <div class="card">
    <table>
      <thead>
        <tr><th>Scenario</th><th>Approach A (Offline+Cache)</th><th>Approach B (Online Stats)</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>Normal booking event</td>
          <td>Reflected in cache within seconds; merged in next batch</td>
          <td>Reflected in store within seconds</td>
        </tr>
        <tr>
          <td>Missed event</td>
          <td>Caught by next nightly batch (max 24hr stale)</td>
          <td>Caught by next reconciliation (max 6hr stale)</td>
        </tr>
        <tr>
          <td>Duplicate event</td>
          <td>source_version prevents double-counting</td>
          <td>source_version prevents double-counting</td>
        </tr>
        <tr>
          <td>Retroactive refund</td>
          <td>Intraday: update cache delta. Next batch: recalculated from SoT</td>
          <td>Cascading update to daily + aggregate rows</td>
        </tr>
        <tr>
          <td>Source of truth inconsistency</td>
          <td>Batch job reads canonical data; inherits any SoT issues</td>
          <td>Reconciliation compares; cannot fix SoT issues, only detect</td>
        </tr>
      </tbody>
    </table>
  </div>
</section>

<!-- ==================== SECTION 8: SURGING ==================== -->
<section id="surging">
  <h2><span class="icon" style="background:linear-gradient(135deg,rgba(252,100,45,0.2),rgba(252,100,45,0.08)); color:var(--accent);">&#128293;</span> Follow-up: Surging Feature</h2>

  <div class="tip-box tip-interview">
    <div class="tip-title">Interview Follow-up Question</div>
    <p>"Now suppose we want to detect high-demand nights in a geographic area within 30 minutes, so we can suggest hosts raise their prices. How would you extend this system?"</p>
  </div>

  <p>The surging feature requires detecting when vacancy rates drop rapidly in a specific geographic area (e.g., San Francisco downtown during a convention). This is fundamentally different from per-listing metrics -- it requires geo-aggregation.</p>

  <div class="comparison">
    <div class="card option-a">
      <div class="card-header" style="color:var(--secondary);">Option A: Per-Geo Counters</div>
      <p style="color:var(--text-muted);margin-bottom:12px;">Increment/decrement counters per geo zone on each booking event</p>

      <h4>Design</h4>
      <ul>
        <li>Define geo zones (e.g., geohash-6 cells, ~1.2km x 0.6km)</li>
        <li>Maintain in Redis: <code class="inline">surge:{geohash}:{date} -> {booked: N, total: M}</code></li>
        <li>On each booking event, atomically increment the booked counter for the listing's geo zone</li>
        <li>Every 30 minutes, scan all geo zones and flag those where <code class="inline">booked/total > 0.85</code></li>
      </ul>

      <h4 style="color:var(--success);">Pros</h4>
      <ul>
        <li>Real-time (within seconds of a booking)</li>
        <li>O(1) per booking event</li>
        <li>Simple scan to detect surges</li>
      </ul>
      <h4 style="color:var(--danger);">Cons</h4>
      <ul>
        <li>Geo boundaries are fixed at setup time</li>
        <li>If geo zones change (e.g., new neighborhood definitions), need to rebuild all counters</li>
        <li>Edge cases: listings near geo boundaries may belong to wrong zone</li>
      </ul>
    </div>

    <div class="card option-b">
      <div class="card-header" style="color:var(--accent);">Option B: Indexed Recalculation</div>
      <p style="color:var(--text-muted);margin-bottom:12px;">Index listings by geo, recompute vacancy per geo every 30 minutes</p>

      <h4>Design</h4>
      <ul>
        <li>Maintain a geo-spatial index of listings (PostGIS, Elasticsearch geo_point)</li>
        <li>Every 30 minutes, for each geo zone: query all listings in the zone, check their current state from listing_daily_metrics, compute vacancy rate</li>
        <li>If vacancy &lt; 15%, trigger surge notification to hosts in that zone</li>
      </ul>

      <h4 style="color:var(--success);">Pros</h4>
      <ul>
        <li>Flexible geo boundaries (can change zone definitions without rebuilding)</li>
        <li>Can support arbitrary geo queries (radius around a point, polygon)</li>
        <li>No counter drift -- recalculates from source data each time</li>
      </ul>
      <h4 style="color:var(--danger);">Cons</h4>
      <ul>
        <li>30-minute latency (not real-time)</li>
        <li>Expensive: 7M listings / ~100 per geo zone = ~70K zones to scan every 30 min</li>
        <li>Requires geo-spatial index maintenance</li>
      </ul>
    </div>
  </div>

  <div class="card">
    <h4>Recommended Hybrid</h4>
    <p>Use <strong>Option A</strong> for real-time surge detection (fixed granularity like geohash-6), and <strong>Option B</strong> for ad-hoc analytics queries (e.g., "what's the vacancy rate in this custom polygon?"). The fixed-geo counters handle the 30-minute SLA easily. The indexed approach is reserved for flexible queries that do not have real-time requirements.</p>
  </div>
</section>

<!-- ==================== SECTION 9: GDPR ==================== -->
<section id="gdpr">
  <h2><span class="icon" style="background:linear-gradient(135deg,rgba(123,47,247,0.2),rgba(123,47,247,0.08)); color:var(--purple);">&#128737;</span> Follow-up: GDPR Compliance</h2>

  <div class="tip-box tip-interview">
    <div class="tip-title">Interview Follow-up Question</div>
    <p>"A user exercises their right to be forgotten under GDPR. We must delete all their personal data within 30 days. How does this affect the metrics system?"</p>
  </div>

  <h3>What Gets Deleted</h3>
  <div class="card">
    <p>GDPR "right to erasure" applies to <strong>personally identifiable information (PII)</strong>. The question is: do aggregated metrics contain PII?</p>
    <table>
      <thead>
        <tr><th>Data</th><th>Contains PII?</th><th>Action Required</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>listing_daily_metrics (listing owned by deleted user)</td>
          <td>Indirectly (listing_id links to deleted user)</td>
          <td>Delete all rows for listings owned by the deleted user</td>
        </tr>
        <tr>
          <td>listing_daily_metrics (listing booked by deleted guest)</td>
          <td>No (booking_id is the guest's PII, but revenue/state is the host's data)</td>
          <td>Nullify booking_id field only; keep revenue data (it belongs to the host)</td>
        </tr>
        <tr>
          <td>listing_aggregate_metrics</td>
          <td>No individual guest PII in aggregates</td>
          <td>Delete rows for deleted host's listings; guest data is already aggregated</td>
        </tr>
        <tr>
          <td>metrics_change_log</td>
          <td>May contain event IDs traceable to user</td>
          <td>Delete log entries containing the user's event IDs</td>
        </tr>
      </tbody>
    </table>
  </div>

  <h3>Approach A: Offline + Cache (GDPR)</h3>
  <div class="card">
    <ul>
      <li><strong>Data warehouse:</strong> Deleted user's data is excluded from warehouse tables during the next ETL run. Standard GDPR deletion in the warehouse propagates automatically.</li>
      <li><strong>Batch output (metrics store):</strong> Next nightly batch will not include the deleted user's listings, so their metrics rows naturally disappear. For the 30-day deadline, we run an on-demand deletion job immediately.</li>
      <li><strong>Intraday cache:</strong> Redis entries for the deleted user's listings are evicted immediately. Cache TTL (typically &lt;24 hours) ensures any missed cache entries expire quickly.</li>
    </ul>
    <div class="tip-box tip-success" style="margin-top:12px;">
      <div class="tip-title">Advantage</div>
      <p>The self-healing nature of nightly batch means GDPR deletions are naturally reinforced every 24 hours. Even if the immediate deletion job misses something, the next batch run will not include the deleted data.</p>
    </div>
  </div>

  <h3>Approach B: Online Stats (GDPR)</h3>
  <div class="card">
    <ul>
      <li><strong>Metrics store:</strong> Requires an explicit deletion interface. When a GDPR deletion request arrives, issue DELETE statements across all metrics tables for the user's listings.</li>
      <li><strong>Event pipeline:</strong> Must ensure no new events for the deleted user's listings are processed after deletion. Add the user/listing to a "deleted entities" blocklist checked by the event consumer.</li>
      <li><strong>Change log:</strong> Scan and delete all change log entries referencing the user's listings or events.</li>
      <li><strong>Reconciliation:</strong> Must be GDPR-aware -- do not "reconcile" deleted data back into existence from a source that hasn't been cleaned yet.</li>
    </ul>
    <div class="tip-box tip-warning" style="margin-top:12px;">
      <div class="tip-title">Risk</div>
      <p>In the online approach, GDPR deletion must touch every storage layer (metrics store, blocklist, change log, any caches). There is no "natural reset" like the batch approach. Missing any layer means PII persists beyond the 30-day deadline -- a compliance violation.</p>
    </div>
  </div>
</section>

<!-- ==================== SECTION 10: TRADE-OFFS ==================== -->
<section id="tradeoffs">
  <h2><span class="icon" style="background:linear-gradient(135deg,rgba(16,185,129,0.2),rgba(16,185,129,0.06)); color:var(--success);">&#9878;</span> Trade-offs Comparison</h2>

  <h3>Approach A vs Approach B</h3>
  <div class="card">
    <table>
      <thead>
        <tr><th>Dimension</th><th>A: Offline + Cache</th><th>B: Online Stats</th><th>Winner</th></tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Data Freshness</strong></td>
          <td>Sub-hour (intraday cache) with nightly full refresh</td>
          <td>Near real-time (seconds)</td>
          <td style="color:var(--accent);">B</td>
        </tr>
        <tr>
          <td><strong>Consistency Recovery</strong></td>
          <td>Self-healing every 24 hours (batch recomputes from SoT)</td>
          <td>Depends on reconciliation job frequency</td>
          <td style="color:var(--secondary);">A</td>
        </tr>
        <tr>
          <td><strong>Operational Complexity</strong></td>
          <td>Two systems (batch + cache) with midnight handoff</td>
          <td>One system (event pipeline) with reconciliation</td>
          <td>Tie</td>
        </tr>
        <tr>
          <td><strong>Code Complexity</strong></td>
          <td>Duplicated logic (batch SQL + cache event handler)</td>
          <td>Single event handler + reconciliation comparator</td>
          <td style="color:var(--accent);">B</td>
        </tr>
        <tr>
          <td><strong>GDPR Deletion</strong></td>
          <td>Naturally cleaned by next batch run</td>
          <td>Must touch all storage layers explicitly</td>
          <td style="color:var(--secondary);">A</td>
        </tr>
        <tr>
          <td><strong>Failure Recovery</strong></td>
          <td>Cache crash: stale for rest of day. Batch crash: retry next night.</td>
          <td>Event consumer crash: backlog builds but catches up. Metrics store crash: data loss if not replicated.</td>
          <td style="color:var(--secondary);">A</td>
        </tr>
        <tr>
          <td><strong>New Metric Types</strong></td>
          <td>Requires changes in batch job AND cache handler</td>
          <td>Add new event handler, backfill via reconciliation</td>
          <td style="color:var(--accent);">B</td>
        </tr>
        <tr>
          <td><strong>Multi-Region</strong></td>
          <td>Batch job runs in one region, replicates output</td>
          <td>Event consumers in each region, partition by geo</td>
          <td>Tie</td>
        </tr>
        <tr>
          <td><strong>Testing</strong></td>
          <td>Batch logic testable in isolation; cache harder to test</td>
          <td>Event handler testable in isolation; reconciliation integration tests needed</td>
          <td>Tie</td>
        </tr>
      </tbody>
    </table>
  </div>

  <h3>Consistency Model Trade-offs</h3>
  <div class="card">
    <table>
      <thead>
        <tr><th>Model</th><th>Description</th><th>Use When</th></tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Eventual (Batch)</strong></td>
          <td>Metrics may lag source of truth by up to 24 hours. Self-correcting.</td>
          <td>Historical analytics, monthly reports, tax documentation</td>
        </tr>
        <tr>
          <td><strong>Eventual (Event-driven)</strong></td>
          <td>Metrics lag by seconds to minutes. Drift possible between reconciliations.</td>
          <td>Host dashboard, real-time earnings tracker</td>
        </tr>
        <tr>
          <td><strong>Strong</strong></td>
          <td>Metrics updated in same transaction as source of truth. Expensive.</td>
          <td>Payment processing, tax calculations (NOT needed for dashboard)</td>
        </tr>
      </tbody>
    </table>
  </div>

  <h3>Per-Listing vs Per-Geo Aggregation</h3>
  <div class="card">
    <table>
      <thead>
        <tr><th>Approach</th><th>Storage Model</th><th>Best For</th><th>Limitation</th></tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Per-Listing</strong></td>
          <td>listing_daily_metrics table, aggregated per listing</td>
          <td>Host dashboard, individual listing performance</td>
          <td>Cross-listing queries require scatter-gather</td>
        </tr>
        <tr>
          <td><strong>Per-Geo</strong></td>
          <td>Geo-zone counters in Redis or geo-indexed table</td>
          <td>Surge detection, market-level analytics</td>
          <td>Fixed geo boundaries, counter drift</td>
        </tr>
        <tr>
          <td><strong>Hybrid</strong></td>
          <td>Per-listing as source of truth, per-geo as derived materialized view</td>
          <td>Both use cases</td>
          <td>Two systems to maintain and keep consistent</td>
        </tr>
      </tbody>
    </table>
  </div>
</section>

<!-- ==================== SECTION 11: INTERVIEW TIPS ==================== -->
<section id="interview-tips">
  <h2><span class="icon" style="background:linear-gradient(135deg,rgba(123,47,247,0.2),rgba(123,47,247,0.08)); color:var(--purple);">&#127891;</span> Interview Tips &amp; Calibration</h2>

  <h3>Level Calibration</h3>
  <div class="card">
    <table>
      <thead>
        <tr><th>Level</th><th>Expected Depth</th><th>Differentiator</th></tr>
      </thead>
      <tbody>
        <tr>
          <td><span class="badge badge-blue" style="margin:0;">L4 (SDE II)</span></td>
          <td>Offline batch-only solution with high latency. Basic aggregation logic. May not address consistency.</td>
          <td>Can compute the right formulas. Proposes a warehouse job. Does not address freshness or consistency.</td>
        </tr>
        <tr>
          <td><span class="badge badge-purple" style="margin:0;">L5 (Senior)</span></td>
          <td>Offline + caching OR online + consistency checks. Handles edge cases. Understands pub/sub requirement.</td>
          <td>Identifies that data sources are separate. Proposes event-driven updates. Addresses missed writes. Discusses idempotency.</td>
        </tr>
        <tr>
          <td><span class="badge badge-red" style="margin:0;">L6 (Staff/PE)</span></td>
          <td>Generalized solution with both approaches compared. Multi-region considerations. Fault tolerance. GDPR. Surging follow-up.</td>
          <td>Deep consistency analysis. Race condition identification. Reconciliation design. Follow-up features integrated. Discusses operational concerns.</td>
        </tr>
      </tbody>
    </table>
  </div>

  <h3>Interview Signal Calibration</h3>
  <div class="calibration-grid">
    <div class="calibration-card cal-strong-no">
      <div class="cal-label">Strong No</div>
      <p><strong>Treats it as a math problem.</strong> Focuses on computing occupancy rate and RevPAR formulas. Proposes direct queries against the booking database. Does not recognize the consistency challenge. Ignores that data sources are separate. No mention of missed writes, stale data, or mutable history.</p>
    </div>
    <div class="calibration-card cal-no">
      <div class="cal-label">No</div>
      <p><strong>Recognizes the problem but cannot handle inconsistencies.</strong> Proposes a batch job or event pipeline but does not address what happens when events are missed. Cannot explain how to detect or correct drift. May mention caching but does not address cache invalidation or midnight handoff. No pub/sub awareness.</p>
    </div>
    <div class="calibration-card cal-yes">
      <div class="cal-label">Yes</div>
      <p><strong>Handles inconsistencies within a day.</strong> Proposes either offline+cache or online+reconciliation. Explains how missed writes are detected and corrected. Discusses idempotent event processing. Understands pub/sub on source-of-truth changes. Addresses the freshness requirement (&lt;1 hour). Can discuss trade-offs between approaches.</p>
    </div>
    <div class="calibration-card cal-strong-yes">
      <div class="cal-label">Strong Yes</div>
      <p><strong>Consistent solution + follow-ups + reliability deep dives.</strong> Presents both approaches with clear trade-off analysis. Identifies race conditions (midnight handoff, reconciliation during writes). Designs the reconciliation job with compare-and-swap semantics. Handles surging follow-up with geo-aggregation trade-offs. Addresses GDPR with approach-specific strategies. Discusses multi-region, monitoring, alerting on drift.</p>
    </div>
  </div>

  <h3>Common Mistakes to Avoid</h3>
  <div class="card">
    <table>
      <thead>
        <tr><th>Mistake</th><th>Why It Hurts</th><th>Better Approach</th></tr>
      </thead>
      <tbody>
        <tr>
          <td>Spending 15 minutes on math formulas</td>
          <td>Occupancy rate is division. The interviewer knows you can do math.</td>
          <td>Define formulas in 2 minutes, then focus on data pipeline and consistency.</td>
        </tr>
        <tr>
          <td>Designing for massive read scale</td>
          <td>~2 QPS. A Raspberry Pi could handle it. Scale is not the challenge here.</td>
          <td>Acknowledge low QPS early. Focus on write consistency and data freshness.</td>
        </tr>
        <tr>
          <td>Ignoring mutable past data</td>
          <td>If you treat metrics as append-only, refunds break everything.</td>
          <td>Design for retroactive updates explicitly. Show cascading recomputation.</td>
        </tr>
        <tr>
          <td>Proposing only one approach</td>
          <td>PE-level candidates are expected to compare alternatives.</td>
          <td>Present offline and online approaches, then reason about which to recommend and why.</td>
        </tr>
        <tr>
          <td>"Just use Kafka" without addressing failure modes</td>
          <td>Kafka has at-least-once delivery, not exactly-once. Messages can be lost in consumer crashes.</td>
          <td>Explain idempotent consumers, dead letter queues, and reconciliation as safety nets.</td>
        </tr>
      </tbody>
    </table>
  </div>

  <h3>Suggested Interview Flow (45 minutes)</h3>
  <div class="card">
    <table>
      <thead>
        <tr><th>Time</th><th>Phase</th><th>Focus</th></tr>
      </thead>
      <tbody>
        <tr>
          <td style="color:var(--primary);font-weight:700;">0-5 min</td>
          <td>Clarify Requirements</td>
          <td>Confirm metrics (occupancy, ANR, RevPAR). Confirm data sources are separate. Confirm past data is mutable. Confirm freshness requirement.</td>
        </tr>
        <tr>
          <td style="color:var(--primary);font-weight:700;">5-8 min</td>
          <td>Capacity Estimates</td>
          <td>Quick napkin math. Emphasize that QPS is low -- this is a consistency problem, not a throughput problem.</td>
        </tr>
        <tr>
          <td style="color:var(--primary);font-weight:700;">8-20 min</td>
          <td>Two Approaches</td>
          <td>Present offline+cache and online+reconciliation. Draw both architectures. State trade-offs clearly.</td>
        </tr>
        <tr>
          <td style="color:var(--primary);font-weight:700;">20-30 min</td>
          <td>Deep Dive: Consistency</td>
          <td>Missed writes detection. Idempotent processing. Reconciliation design. Race conditions.</td>
        </tr>
        <tr>
          <td style="color:var(--primary);font-weight:700;">30-35 min</td>
          <td>Data Model + API</td>
          <td>Schema for daily and aggregate tables. Show the dashboard query path.</td>
        </tr>
        <tr>
          <td style="color:var(--primary);font-weight:700;">35-45 min</td>
          <td>Follow-ups</td>
          <td>Surging (geo-aggregation). GDPR (per-approach deletion strategy). Multi-region if time permits.</td>
        </tr>
      </tbody>
    </table>
  </div>

  <div class="tip-box tip-interview">
    <div class="tip-title">The One Sentence That Gets You to "Strong Yes"</div>
    <p>"The core challenge here is not computing occupancy rate -- it is maintaining a derived data store that stays consistent with multiple upstream sources of truth, even when events are missed, duplicated, or arrive out of order, and when past data can change retroactively." If you communicate this framing early, the interviewer knows you understand the problem at a PE level.</p>
  </div>
</section>

</div>

<!-- ==================== FOOTER ==================== -->
<div class="footer">
  <p><a href="index.html">&#8592; All Topics</a> &nbsp;|&nbsp; <a href="../index.html">Airbnb System Design Home</a></p>
  <p style="margin-top: 8px;">Topic 5 of 18 -- Aggregated Listing Metrics -- Principal Engineer Interview Prep</p>
</div>

<script>
(function(){
  document.querySelectorAll(".diagram-box").forEach(function(box){
    var svg=box.querySelector("svg");
    if(!svg) return;
    var zoom=1, minZ=0.5, maxZ=3;
    var ctrl=document.createElement("div");
    ctrl.className="diagram-zoom-controls";
    ctrl.innerHTML='<button class="zoom-out" title="Zoom Out"></button><span class="zoom-level">100%</span><button class="zoom-in" title="Zoom In">+</button><button class="zoom-reset" title="Reset"></button><button class="zoom-fs" title="Fullscreen"></button>';
    box.insertBefore(ctrl,box.firstChild);
    var lvl=ctrl.querySelector(".zoom-level");
    function apply(){svg.style.transform="scale("+zoom+")";lvl.textContent=Math.round(zoom*100)+"%";}
    ctrl.querySelector(".zoom-in").onclick=function(){zoom=Math.min(maxZ,zoom+0.25);apply();};
    ctrl.querySelector(".zoom-out").onclick=function(){zoom=Math.max(minZ,zoom-0.25);apply();};
    ctrl.querySelector(".zoom-reset").onclick=function(){zoom=1;apply();};
    ctrl.querySelector(".zoom-fs").onclick=function(){
      box.classList.toggle("fullscreen");
      if(box.classList.contains("fullscreen")){this.textContent="";zoom=1.2;}else{this.textContent="";zoom=1;}
      apply();
    };
    box.addEventListener("wheel",function(e){
      if(e.ctrlKey){e.preventDefault();zoom=e.deltaY<0?Math.min(maxZ,zoom+0.1):Math.max(minZ,zoom-0.1);apply();}
    },{passive:false});
  });
})();
</script>
</body>
</html>
